<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-CN">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">

<script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
<link href="//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/panfengblog/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/panfengblog/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/panfengblog/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/panfengblog/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/panfengblog/images/favicon.ico?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/panfengblog/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/panfengblog/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="算法,python,分类," />










<meta name="description" content="Logistic回归原理分析和实践参考资料：  机器学习   周志华 统计学习方法 李航 一些博客：logistic回归详解,详解最大似然估计（MLE）、最大后验概率估计（MAP），以及贝叶斯公式的理解,逻辑回归（Logistic Regression）-牛顿法求解参数">
<meta property="og:type" content="article">
<meta property="og:title" content="Logistic回归原理分析和实践">
<meta property="og:url" content="http://coolguo.gitee.io/2020/07/13/Logistic%E5%9B%9E%E5%BD%92%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90%E5%92%8C%E5%AE%9E%E8%B7%B5/index.html">
<meta property="og:site_name" content="panfengblog">
<meta property="og:description" content="Logistic回归原理分析和实践参考资料：  机器学习   周志华 统计学习方法 李航 一些博客：logistic回归详解,详解最大似然估计（MLE）、最大后验概率估计（MAP），以及贝叶斯公式的理解,逻辑回归（Logistic Regression）-牛顿法求解参数">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s1.ax1x.com/2020/07/09/Um1cdS.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/07/10/UuPHc4.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/07/13/UJTwo6.png">
<meta property="article:published_time" content="2020-07-13T08:18:31.860Z">
<meta property="article:modified_time" content="2020-07-13T08:20:16.305Z">
<meta property="article:author" content="panfeng&#39;s blog">
<meta property="article:tag" content="算法">
<meta property="article:tag" content="python">
<meta property="article:tag" content="分类">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s1.ax1x.com/2020/07/09/Um1cdS.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/panfengblog/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://coolguo.gitee.io/2020/07/13/Logistic回归原理分析和实践/"/>





  <title>Logistic回归原理分析和实践 | panfengblog</title>
  








<meta name="generator" content="Hexo 4.2.0"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>
	<a href="https://github.com/AgentGuo" target="_blank" rel="noopener" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/panfengblog/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">panfengblog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/panfengblog/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/panfengblog/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/panfengblog/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://coolguo.gitee.io/panfengblog/2020/07/13/Logistic%E5%9B%9E%E5%BD%92%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90%E5%92%8C%E5%AE%9E%E8%B7%B5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="panfeng's blog">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://note.youdao.com/yws/api/personal/file/94706D7C9BE34FFEBAD4C35B311F0E38?method=download&shareKey=5a712edcc9469413b507c8ef9cf15513">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="panfengblog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Logistic回归原理分析和实践</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-07-13T16:18:31+08:00">
                2020-07-13
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/panfengblog/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/panfengblog/2020/07/13/Logistic%E5%9B%9E%E5%BD%92%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90%E5%92%8C%E5%AE%9E%E8%B7%B5/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2020/07/13/Logistic回归原理分析和实践/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  2.6k
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="Logistic回归原理分析和实践"><a href="#Logistic回归原理分析和实践" class="headerlink" title="Logistic回归原理分析和实践"></a>Logistic回归原理分析和实践</h1><p>参考资料：</p>
<ul>
<li>机器学习   周志华</li>
<li>统计学习方法 李航</li>
<li>一些博客：<a href="https://blog.csdn.net/tian_tian_hero/article/details/89409472" target="_blank" rel="noopener">logistic回归详解</a>,<a href="https://blog.csdn.net/u011508640/article/details/72815981" target="_blank" rel="noopener">详解最大似然估计（MLE）、最大后验概率估计（MAP），以及贝叶斯公式的理解</a>,<a href="https://blog.csdn.net/Fishmemory/article/details/51603836?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.compare&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.compare" target="_blank" rel="noopener">逻辑回归（Logistic Regression）-牛顿法求解参数</a></li>
</ul>
<a id="more"></a>
<h2 id="原理分析"><a href="#原理分析" class="headerlink" title="原理分析"></a>原理分析</h2><h3 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h3><p>这里介绍Logisitic回归首先从线性回归讲起（logistic回归其实就是一种广义的线性回归）。</p>
<p>线性模型（linear model）试图学得一个通过属性的线性组合来进行的预测的函数（假设给定d个属性，$\pmb{x}=[x_1,x_2,…,x_d]$），即：</p>
<script type="math/tex; mode=display">f(x)=w_1x_1+w_2x_2+...+w_dx_d+b</script><p>写成矩阵形式（$\pmb{w}=[w_1,w_2,…,w_d]$）：</p>
<script type="math/tex; mode=display">f(x)=\pmb{w^Tx}+b</script><p>“线性回归”（linear regression）试图学得一个线性模型以尽可能准确的预测<strong>实值</strong>输出。（其求解参数方法在此不做过多介绍）</p>
<p>线性模型虽然简单，但是却有着丰富的变化，假如我们所需要求解的输出可能在指数尺度上变化，那么我们可能需要以下的线性模型：</p>
<script type="math/tex; mode=display">lny=\pmb{w^Tx}+b</script><p>这就是“对数线性回归”（log-linear-regression），它实际上是在试图让$e^{\pmb{w^Tx}+b}$去逼近$y$，但是写成上述形式仍是线性回归，实际上已经是在求一种非线性关系。</p>
<p>更一般的，考虑单调可微函数$g(.)$，令：</p>
<script type="math/tex; mode=display">y=g^{-1}(\pmb{w^Tx}+b)</script><p>这样得到模型称为“广义线性模型”（generalized linear model），其中$g(.)$称为“联系函数”（link function），上述对数线性函数就是广义线性函数当$g(.)=ln(.)$的一种特例。</p>
<h3 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h3><p>线性回归表现为输入与输出的一种线性关系，而逻辑回归直观上表现了0，1分类的形式（比如预测未来经济增长可能个线性回归问题，但是预测一张图片是猫咪还是狗狗就是一个逻辑回归问题）</p>
<p>但是我们可以使用上述提到的广义线性模型来实现。</p>
<p>考虑二分类任务，其输出标记$y\in\left\{ 0,1  \right\}$，而线性回归模型产生的预测值$z=\pmb{w^Tx}+b$是实值，于是我们只需要将实值z转化为0/1值，可以使用以下的“单位跃迁函数”（unit-step function）</p>
<script type="math/tex; mode=display">f(x)=\left\{ \begin{aligned} 0,\,\,\,z<0 \\ 0/1,\,\,\,z=0 \\ 1,\,\,\,z>0 \end{aligned} \right.</script><p>即若预测值大于0就判正例，小于0则判反例，等于0可任意判别。</p>
<p>但是单位跃迁函数不连续，因此不能直接用作广义线性模型的$g(.)$，因此我们希望找到一定程度上近似单位跃迁函数的函数，并且希望它满足单调可微，对数几率函数（Logistic function）正好就满足（如下）。</p>
<script type="math/tex; mode=display">y=\cfrac{1}{1+e^{-z}}</script><p><img src="https://s1.ax1x.com/2020/07/09/Um1cdS.png" alt="Um1cdS.png"></p>
<p>可以从上图中看出，对数几率函数是一种“Sigmoid函数”（即形如S的函数，对率函数就是其中最重要的代表），将对数几率函数带入广义线性模型可以得到下式：</p>
<script type="math/tex; mode=display">y=\cfrac{1}{1+e^{\pmb{w^Tx}+b}}</script><p>将上式进行一些变形：</p>
<script type="math/tex; mode=display">ln\cfrac{y}{1-y}=\pmb{w^Tx}+b</script><p>若将$y$视为样本$\pmb{x}$作为正例的可能性，则$1-y$是其反例可能性，二者的比值$\cfrac{y}{1-y}$称为几率（odds），反应了样本$\pmb{x}$作为正例的<strong>相对可能性</strong>，对几率取对数得到“对数几率”（log odds，亦称logit）$ln\cfrac{y}{1-y}$</p>
<p>由此可以看出逻辑回归实际上就是在用线性回归模型的预测结果去逼近真实标记的对数几率，因此其对应的模型称为“对数几率回归”（logistic regression），逻辑回归就是其音译的结果，中文“逻辑”和“logistic”的含义相差甚远。值得注意的是，虽然它的名字里面是“回归”，但它实际上是一种分类学习方法。</p>
<h3 id="逻辑回归参数的求解"><a href="#逻辑回归参数的求解" class="headerlink" title="逻辑回归参数的求解"></a>逻辑回归参数的求解</h3><p>一些符号的说明：$a_i=\cfrac{1}{1+e^{\pmb{w^Tx_i}+b}}$，$z_i=\pmb{w^Tx_i}+b$，学习率：$\alpha$</p>
<h4 id="1-损失函数"><a href="#1-损失函数" class="headerlink" title="1.损失函数"></a>1.损失函数</h4><p>我们通过“极大似然法”来估计参数$\pmb{w}$和$b$，</p>
<p>我们首先定义最大似然函数（认为各个样本之间是相对独立的），</p>
<script type="math/tex; mode=display">l(\pmb{w},b)=\prod_{i=1}^{m}p(y_i|\pmb{x_i};\pmb{w},b)=\prod_{i=1}^{m}a^{y_i}_i(1-a_i)^{1-y_i}</script><p>如果使用一般最大似然会出现概率连乘的表达式，容易造成数值溢出，因此在采用对数似然（并且更容易进行求导），将连乘结果转化为累加：</p>
<script type="math/tex; mode=display">ln \, l(\pmb{w},b)=\sum_{i=1}^{m}ln\,p(y|\pmb{x};\pmb{w},b)=\sum_{i=1}^{m}y_i lna_i+(1-y_i)ln(1-a_i)</script><p>我们定义以下的损失函数：</p>
<script type="math/tex; mode=display">J(\pmb{w},b)=-ln \, l(\pmb{w},b)=-(\sum_{i=1}^{m}y_i lna_i+(1-y_i)ln(1-a_i))</script><p>之前的似然函数是取最大值的，我们定义的损失函数等于对数似然的相反数，所以损失函数是需要取最小值的（所以对应的是<strong>梯度下降法</strong>，你可能也听说过<strong>梯度上升法</strong>，其实是一回事，只是损失函数的定义不同罢了）。</p>
<h4 id="2-1梯度下降法"><a href="#2-1梯度下降法" class="headerlink" title="2.1梯度下降法"></a>2.1梯度下降法</h4><p>对于一个样本，使用链式规则，依次求导：</p>
<script type="math/tex; mode=display">\cfrac{\partial J}{\partial a_i}=-\cfrac{y_i}{a_i}+\cfrac{1-y_i}{1-a_i}</script><script type="math/tex; mode=display">\cfrac{\partial J}{\partial z_i}=\cfrac{\partial J}{\partial a_i}\cfrac{\partial a_i}{\partial z_i}=a_i-y_i</script><script type="math/tex; mode=display">\cfrac{\partial J}{\partial \pmb{w}}=\cfrac{\partial J}{\partial z_i}\cfrac{\partial z_i}{\partial \pmb{w}}=\pmb{x_i}(a_i-y_i)$$（注：这里求出的导数是一个 1xd 的向量）

$$\cfrac{\partial J}{\partial b}=\cfrac{\partial J}{\partial z_i}\cfrac{\partial z_i}{\partial b}=a_i-y_i</script><p>对于m个样本，只需要求平均即可：</p>
<script type="math/tex; mode=display">\cfrac{\partial J}{\partial \pmb{w}}=\cfrac{1}{m}\sum_{i=1}^{m}\pmb{x_i}(a_i-y_i)</script><script type="math/tex; mode=display">\cfrac{\partial J}{\partial b}=\cfrac{1}{m}(a_i-y_i)</script><p>然后更新$\pmb{w}$和$b$</p>
<script type="math/tex; mode=display">\pmb{w}:=\pmb{w}-\alpha \cfrac{\partial J}{\partial \pmb{w}}=\pmb{w}-\alpha \cfrac{1}{m}\sum_{i=1}^{m}\pmb{x_i}(a_i-y_i)</script><script type="math/tex; mode=display">b:=b-\alpha \cfrac{\partial J}{\partial b}=b-\alpha \cfrac{1}{m}\sum_{i=1}^{m}(a_i-y_i)</script><h4 id="2-2-牛顿法"><a href="#2-2-牛顿法" class="headerlink" title="2.2 牛顿法"></a>2.2 牛顿法</h4><p>和梯度下降法类似，都是通过迭代算法来实现的。</p>
<p>首先我们来看这么一个问题，$f(x)=0$有近似根$x_k$，那么$f(x)$在点$x_k$处的泰勒展开式表示为：$f(x)\approx f(x_k) + f’(x_k)(x-x_k)$</p>
<p>令$f(x)=0$，那么就有$f(x_k)+f’(x-x_k)=0$，由此就可求解$x=x_k-\cfrac{f(x_k)}{f’(x_k)}$</p>
<p>对于凸函数而言，这样的一次迭代过程就会进一步的接近极小值，直观理解可以查看下图：</p>
<p><img src="https://s1.ax1x.com/2020/07/10/UuPHc4.png" alt="UuPHc4.png"></p>
<p>由于我们的损失函数是一个高阶可导的连续凸函数（令$\pmb{\beta}=[\pmb{w}|b]$），所以我们令上述的$f(x)=J’(\pmb{\beta})$，当$J’(\pmb{\beta})=0$时即为最优解，所以我们就能够这样来更新参数：$\pmb{\beta} = \pmb{\beta}-\cfrac{\partial J}{\partial  \pmb{\beta}} (\cfrac{\partial^2 J}{\partial  \pmb{\beta}\partial  \pmb{\beta^T}})^{-1}$</p>
<p>这就是牛顿法，其中$H=(\cfrac{\partial^2 J}{\partial  \pmb{\beta}\partial  \pmb{\beta^T}})^{-1}$被称为黑塞矩阵（Hessian Matrix），由于其不一定可逆（并且求逆的计算量比较大），所以一般使用的时拟牛顿法，拟牛顿法在这就不过多介绍了。（实践中牛顿法和拟牛顿法都没有使用）</p>
<h2 id="Logistic回归实践"><a href="#Logistic回归实践" class="headerlink" title="Logistic回归实践"></a>Logistic回归实践</h2><p>逻辑回归实践使用是Pima印第安人数据集，该数据集最初来自国家糖尿病/消化/肾脏疾病研究所。数据集的目标是基于数据集中包含的某些诊断测量来诊断性的预测 患者是否患有糖尿病。整个实践过程没有使用任何的<strong>机器学习库</strong>，需要完整代码可以点击这里，<a href="https://github.com/AgentGuo/logistic_regression" target="_blank" rel="noopener">点击这里</a>。</p>
<p>python3开发环境说明：</p>
<ul>
<li><code>numpy</code>:<code>1.15.4</code></li>
<li><code>matplotlib</code>:<code>2.2.3</code></li>
</ul>
<h3 id="1-加载数据"><a href="#1-加载数据" class="headerlink" title="1. 加载数据"></a>1. 加载数据</h3><p>数据集（Pima.csv）共有9个特征，分别如下：</p>
<ul>
<li>Pregnancies：怀孕次数 </li>
<li>Glucose：葡萄糖 </li>
<li>BloodPressure：血压 </li>
<li>SkinThickness：皮层厚度</li>
<li>Insulin：胰岛素 2小时血清胰岛素</li>
<li>BMI：体重指数 （体重/身高）^2 </li>
<li>DiabetesPedigreeFunction：糖尿病谱系功能 </li>
<li>Age：年龄 （岁） </li>
<li>Outcome：类标变量 （0或1）</li>
</ul>
<p>将数据加载到矩阵中（将特征和最终的结果分开保存）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">pimaForm = np.loadtxt(<span class="string">'Pima.csv'</span>, dtype=np.float64, delimiter=<span class="string">','</span>)   <span class="comment"># 加载整个表格</span></span><br><span class="line">data = pimaForm[:,:<span class="number">8</span>].T   <span class="comment"># 数据部分</span></span><br><span class="line">label = pimaForm[:,<span class="number">8</span>:].astype(np.int16)   <span class="comment"># 标签部分</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(data.shape, label.shape)</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(8, 768) (768, 1)</span><br></pre></td></tr></table></figure>
<h3 id="2-数据预处理"><a href="#2-数据预处理" class="headerlink" title="2. 数据预处理"></a>2. 数据预处理</h3><h4 id="2-1-缺失值处理"><a href="#2-1-缺失值处理" class="headerlink" title="2.1 缺失值处理"></a>2.1 缺失值处理</h4><p>我们简单的直接使用均值填充了缺失值</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">dataMean = data.mean(axis=<span class="number">1</span>)    <span class="comment"># 计算均值，用于缺失值填充</span></span><br><span class="line">dataStd = data.std(axis=<span class="number">1</span>)      <span class="comment"># 计算标准差，用于后续数据处理</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(data.shape[<span class="number">0</span>]):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(data.shape[<span class="number">1</span>]):</span><br><span class="line">        <span class="keyword">if</span> data[i][j] == <span class="number">0</span>:    <span class="comment"># 出现缺失值就用均值填充</span></span><br><span class="line">            data[i][j] = dataMean[i]</span><br></pre></td></tr></table></figure>
<h4 id="2-2-输出归一化"><a href="#2-2-输出归一化" class="headerlink" title="2.2 输出归一化"></a>2.2 输出归一化</h4><p>认为输入数据为正态分布，然后进行归一化处理</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data = ((data.T - dataMean)/dataStd).T  <span class="comment"># 使用z-score标准化方法</span></span><br></pre></td></tr></table></figure>
<h4 id="2-3-数据集划分"><a href="#2-3-数据集划分" class="headerlink" title="2.3 数据集划分"></a>2.3 数据集划分</h4><p>训练集和测试集按照 5:1 的比例划分</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">testData = data[:,:<span class="number">128</span>]</span><br><span class="line">testLabel = label[:<span class="number">128</span>]</span><br><span class="line">trainData = data[:,<span class="number">128</span>:]</span><br><span class="line">trainLabel = label[<span class="number">128</span>:]</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(testData.shape, testLabel.shape, trainData.shape, trainLabel.shape)</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(8, 128) (128, 1) (8, 640) (640, 1)</span><br></pre></td></tr></table></figure>
<h3 id="3-初始化参数"><a href="#3-初始化参数" class="headerlink" title="3. 初始化参数"></a>3. 初始化参数</h3><p>对参数进行随机初始化：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">initParameter</span><span class="params">(feature_num)</span>:</span></span><br><span class="line">    w = np.random.rand(<span class="number">1</span>, feature_num)   <span class="comment"># w:1xfeature_num, 用0-1随机数初始化</span></span><br><span class="line">    b = <span class="number">0</span>    <span class="comment"># b初始化为0</span></span><br><span class="line">    <span class="keyword">return</span> w,b</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">test_w, test_b = initParameter(<span class="number">8</span>)   <span class="comment"># 测试一下</span></span><br><span class="line">print(test_w.shape, test_b)</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(1, 8) 0</span><br></pre></td></tr></table></figure>
<h3 id="4-向前传播"><a href="#4-向前传播" class="headerlink" title="4. 向前传播"></a>4. 向前传播</h3><p>先计算线性模型，然后再带入sigmoid函数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(data, w, b)</span>:</span></span><br><span class="line">    z = np.dot(w, data)   <span class="comment"># 计算线性部分</span></span><br><span class="line">    a = <span class="number">1</span>/(<span class="number">1</span>+np.exp(-z))  <span class="comment"># 计算预测结果</span></span><br><span class="line">    <span class="keyword">return</span> a.T</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = forward(trainData, test_w, test_b)</span><br><span class="line">print(a.shape)</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(640, 1)</span><br></pre></td></tr></table></figure>
<h3 id="5-梯度下降"><a href="#5-梯度下降" class="headerlink" title="5. 梯度下降"></a>5. 梯度下降</h3><p>反向求导过程</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gradDescent</span><span class="params">(w, b, x , y, a, learning_rate)</span>:</span></span><br><span class="line">    w = w - learning_rate * np.dot(x, a-y).T / a.shape[<span class="number">0</span>]   <span class="comment"># 更新参数w</span></span><br><span class="line">    b = b - learning_rate * (a-y).sum(axis=<span class="number">0</span>)[<span class="number">0</span>]   <span class="comment"># 更新参数b</span></span><br><span class="line">    <span class="keyword">return</span> w,b</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">test_w2, test_b2 = gradDescent(test_w, test_b, trainData, trainLabel, a, <span class="number">0.01</span>)</span><br><span class="line">print(test_w2.shape, test_b2)</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(1, 8) -1.3182942043705952</span><br></pre></td></tr></table></figure>
<h3 id="6-开始训练"><a href="#6-开始训练" class="headerlink" title="6. 开始训练"></a>6. 开始训练</h3><p>就是不断循环向前传播和梯度下降的一个过程：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">w, b = initParameter(<span class="number">8</span>)   <span class="comment"># 测试一下</span></span><br><span class="line">cost = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">200</span>):</span><br><span class="line">    a = forward(trainData, w, b)</span><br><span class="line">    w, b = gradDescent(w, b, trainData, trainLabel, a, <span class="number">0.4</span>)</span><br><span class="line">    cost.append((-(trainLabel*np.log(a)+(<span class="number">1</span>-trainLabel)*np.log(<span class="number">1</span>-a))).sum(axis = <span class="number">0</span>)[<span class="number">0</span>]/a.shape[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(cost)</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<p><img src="https://s1.ax1x.com/2020/07/13/UJTwo6.png" alt="UJTwo6.png"></p>
<p>然后进行<strong>预测</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">testPred = (forward(testData, w, b)&gt;<span class="number">0.5</span>).astype(np.int16)</span><br><span class="line">print(<span class="string">"测试集正确率："</span>+str((testPred==testLabel).astype(np.int16).reshape(<span class="number">-1</span>).sum()/testPred.shape[<span class="number">0</span>]))</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">测试集正确率：0.734375</span><br></pre></td></tr></table></figure>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/panfengblog/tags/%E7%AE%97%E6%B3%95/" rel="tag"><i class="fa fa-tag"></i> 算法</a>
          
            <a href="/panfengblog/tags/python/" rel="tag"><i class="fa fa-tag"></i> python</a>
          
            <a href="/panfengblog/tags/%E5%88%86%E7%B1%BB/" rel="tag"><i class="fa fa-tag"></i> 分类</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/panfengblog/2020/07/08/sklearn%E4%B8%ADPCA%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/" rel="next" title="sklearn中PCA使用方法">
                <i class="fa fa-chevron-left"></i> sklearn中PCA使用方法
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/panfengblog/2020/07/13/%E5%86%B3%E7%AD%96%E6%A0%91%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90%E4%B8%8E%E5%AE%9E%E8%B7%B5/" rel="prev" title="决策树原理分析与实践">
                决策树原理分析与实践 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div class="ds-thread" data-thread-key="2020/07/13/Logistic回归原理分析和实践/"
           data-title="Logistic回归原理分析和实践" data-url="http://coolguo.gitee.io/2020/07/13/Logistic%E5%9B%9E%E5%BD%92%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90%E5%92%8C%E5%AE%9E%E8%B7%B5/">
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="https://note.youdao.com/yws/api/personal/file/94706D7C9BE34FFEBAD4C35B311F0E38?method=download&shareKey=5a712edcc9469413b507c8ef9cf15513"
                alt="panfeng's blog" />
            
              <p class="site-author-name" itemprop="name">panfeng's blog</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/panfengblog/archives">
              
                  <span class="site-state-item-count">21</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/panfengblog/categories/index.html">
                  <span class="site-state-item-count">9</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/panfengblog/tags/index.html">
                  <span class="site-state-item-count">31</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/AgentGuo" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:841796600@qq.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Logistic回归原理分析和实践"><span class="nav-number">1.</span> <span class="nav-text">Logistic回归原理分析和实践</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#原理分析"><span class="nav-number">1.1.</span> <span class="nav-text">原理分析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#线性回归"><span class="nav-number">1.1.1.</span> <span class="nav-text">线性回归</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#逻辑回归"><span class="nav-number">1.1.2.</span> <span class="nav-text">逻辑回归</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#逻辑回归参数的求解"><span class="nav-number">1.1.3.</span> <span class="nav-text">逻辑回归参数的求解</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-损失函数"><span class="nav-number">1.1.3.1.</span> <span class="nav-text">1.损失函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1梯度下降法"><span class="nav-number">1.1.3.2.</span> <span class="nav-text">2.1梯度下降法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-牛顿法"><span class="nav-number">1.1.3.3.</span> <span class="nav-text">2.2 牛顿法</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Logistic回归实践"><span class="nav-number">1.2.</span> <span class="nav-text">Logistic回归实践</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-加载数据"><span class="nav-number">1.2.1.</span> <span class="nav-text">1. 加载数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-数据预处理"><span class="nav-number">1.2.2.</span> <span class="nav-text">2. 数据预处理</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-缺失值处理"><span class="nav-number">1.2.2.1.</span> <span class="nav-text">2.1 缺失值处理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-输出归一化"><span class="nav-number">1.2.2.2.</span> <span class="nav-text">2.2 输出归一化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-3-数据集划分"><span class="nav-number">1.2.2.3.</span> <span class="nav-text">2.3 数据集划分</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-初始化参数"><span class="nav-number">1.2.3.</span> <span class="nav-text">3. 初始化参数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-向前传播"><span class="nav-number">1.2.4.</span> <span class="nav-text">4. 向前传播</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-梯度下降"><span class="nav-number">1.2.5.</span> <span class="nav-text">5. 梯度下降</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-开始训练"><span class="nav-number">1.2.6.</span> <span class="nav-text">6. 开始训练</span></a></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">panfeng's blog</span>

  
</div>

<!--

  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>

 -->

<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共40.9k字</span>
</div>
        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/panfengblog/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/panfengblog/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/panfengblog/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/panfengblog/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/panfengblog/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/panfengblog/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/panfengblog/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/panfengblog/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/panfengblog/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/panfengblog/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/panfengblog/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/panfengblog/js/src/bootstrap.js?v=5.1.4"></script>



  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"your-duoshuo-shortname"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>

  
    
    
    <script src="/panfengblog/lib/ua-parser-js/dist/ua-parser.min.js?v=0.7.9"></script>
    <script src="/panfengblog/js/src/hook-duoshuo.js"></script>
  


















  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
  


  

  

</body>
</html>
