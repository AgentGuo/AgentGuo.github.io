<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-CN">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">

<script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
<link href="//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />










  <meta name="baidu-site-verification" content="code-o4T2nkcjRx" />







  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.ico?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="算法,python,分类,kaggle," />










<meta name="description" content="决策树原理分析与实践决策树零基础入门到实践，理论部分：会介绍决策树的生成，决策树的各种种类（ID3、C4.5、CART）以及一些数据处理（缺失值和连续值）和优化（预剪枝和后剪枝）。实践部分：以Kaggle著名的Titanic数据集（点击这里）为基础，不使用任何机器学习库完成的一颗CART决策树，并且最后进行了后剪枝操作（能看到明显的优化效果，需要完整代码和数据的可以点击这里：点我）。">
<meta property="og:type" content="article">
<meta property="og:title" content="决策树原理分析与实践">
<meta property="og:url" content="http://yoursite.com/2020/07/13/%E5%86%B3%E7%AD%96%E6%A0%91%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90%E4%B8%8E%E5%AE%9E%E8%B7%B5/index.html">
<meta property="og:site_name" content="panfengblog">
<meta property="og:description" content="决策树原理分析与实践决策树零基础入门到实践，理论部分：会介绍决策树的生成，决策树的各种种类（ID3、C4.5、CART）以及一些数据处理（缺失值和连续值）和优化（预剪枝和后剪枝）。实践部分：以Kaggle著名的Titanic数据集（点击这里）为基础，不使用任何机器学习库完成的一颗CART决策树，并且最后进行了后剪枝操作（能看到明显的优化效果，需要完整代码和数据的可以点击这里：点我）。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://s1.ax1x.com/2020/07/10/UM8G8S.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/07/10/UMtUzT.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/07/11/UMHj0S.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/07/11/UMqFCd.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/07/11/UMOwcR.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/07/11/UMOrB6.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/07/11/UMOcND.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/07/12/U1yZXd.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/07/12/UGPP1I.png">
<meta property="og:image" content="https://s1.ax1x.com/2020/07/13/UGU8rq.png">
<meta property="article:published_time" content="2020-07-13T08:18:31.862Z">
<meta property="article:modified_time" content="2020-07-27T14:39:15.742Z">
<meta property="article:author" content="panfeng&#39;s blog">
<meta property="article:tag" content="算法">
<meta property="article:tag" content="python">
<meta property="article:tag" content="分类">
<meta property="article:tag" content="kaggle">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://s1.ax1x.com/2020/07/10/UM8G8S.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2020/07/13/决策树原理分析与实践/"/>





  <title>决策树原理分析与实践 | panfengblog</title>
  








<meta name="generator" content="Hexo 4.2.0"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>
	<a href="https://github.com/AgentGuo" target="_blank" rel="noopener" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">panfengblog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/07/13/%E5%86%B3%E7%AD%96%E6%A0%91%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90%E4%B8%8E%E5%AE%9E%E8%B7%B5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="panfeng's blog">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://note.youdao.com/yws/api/personal/file/94706D7C9BE34FFEBAD4C35B311F0E38?method=download&shareKey=5a712edcc9469413b507c8ef9cf15513">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="panfengblog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">决策树原理分析与实践</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2020-07-13T16:18:31+08:00">
                2020-07-13
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/07/13/%E5%86%B3%E7%AD%96%E6%A0%91%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90%E4%B8%8E%E5%AE%9E%E8%B7%B5/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2020/07/13/决策树原理分析与实践/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2020/07/13/%E5%86%B3%E7%AD%96%E6%A0%91%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90%E4%B8%8E%E5%AE%9E%E8%B7%B5/" class="leancloud_visitors" data-flag-title="决策树原理分析与实践">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Visitors&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  7.8k
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="决策树原理分析与实践"><a href="#决策树原理分析与实践" class="headerlink" title="决策树原理分析与实践"></a>决策树原理分析与实践</h1><p>决策树零基础入门到实践，<strong>理论部分</strong>：会介绍决策树的生成，决策树的各种种类（ID3、C4.5、CART）以及一些数据处理（缺失值和连续值）和优化（预剪枝和后剪枝）。<strong>实践部分</strong>：以Kaggle著名的Titanic数据集（<a href="https://www.kaggle.com/c/titanic" target="_blank" rel="noopener">点击这里</a>）为基础，不使用任何机器学习库完成的一颗CART决策树，并且最后进行了后剪枝操作（能看到明显的优化效果，需要完整代码和数据的可以点击这里：<a href="https://github.com/AgentGuo/decision_tree" target="_blank" rel="noopener">点我</a>）。</p>
<a id="more"></a>
<h2 id="原理分析"><a href="#原理分析" class="headerlink" title="原理分析"></a>原理分析</h2><h3 id="1-简要介绍"><a href="#1-简要介绍" class="headerlink" title="1.简要介绍"></a>1.简要介绍</h3><p>当我们判断“一个瓜是好瓜吗？”是，我们可能会想，①它是青绿色的吗？如果是的，②那么它的根蒂是否卷缩？，如果是的，③那么它的敲击声是否浊响？如果都满足，那么它大概率就是一个好瓜，这个决策的过程其实就是形成了下面一个决策树（图片采用自西瓜书）</p>
<p><img src="https://s1.ax1x.com/2020/07/10/UM8G8S.png" alt="UM8G8S.png"></p>
<h3 id="2-决策树的生成过程"><a href="#2-决策树的生成过程" class="headerlink" title="2.决策树的生成过程"></a>2.决策树的生成过程</h3><p>一些符号说明：</p>
<p>属性集：$A=\left\{ a_1,a_2,…,a_d  \right\}$（假设样本共d个属性，比如上文提到的色泽、根蒂和敲声等等）</p>
<p>数据集：$D=\left\{ (x_1,y_1),(x_2,y_2),…,(x_m,y_m)  \right\}$（假设共m个样本，$x_i$中包含样本的$d$个属性，$y_i$为类别，即保存样本是否为一个好瓜）</p>
<p>以下就是决策树生成的伪代码（图片采自西瓜书，加了一点笔记）：</p>
<p><img src="https://s1.ax1x.com/2020/07/10/UMtUzT.png" alt="UMtUzT.png"></p>
<p>生成决策树就是一个递归的过程（当然很多树的构建也是这样），设置了三个递归的出口：①当类别都相同时，无需继续划分；②没有能够用来划分的属性；③当前集合以为空，当程序都没有从三个出口退出时就说明当前能够划分，然后递归调用即可。</p>
<p>决策树的种类有很多（ID3决策树，C4.5决策树和CART决策树等），他们的生成过程都是相同的，他的区别就是在于代码第8行处选择最优属性方法的不同（也就适用于不同的数据和场景）。</p>
<h3 id="3-选择最优划分属性"><a href="#3-选择最优划分属性" class="headerlink" title="3.选择最优划分属性"></a>3.选择最优划分属性</h3><h4 id="3-1-信息增益（ID3决策树）"><a href="#3-1-信息增益（ID3决策树）" class="headerlink" title="3.1 信息增益（ID3决策树）"></a>3.1 信息增益（ID3决策树）</h4><p>我们都听说过熵，大致是用于描述一个系统的混乱程度，在计算机领域也差不多，称为<strong>信息熵</strong>（information entropy）。</p>
<p>设样本集$D=\left\{ (x_1,y_1),(x_2,y_2),…,(x_m,y_m)  \right\}$中有$|Y|$个类别（比如好瓜和坏瓜就两个类别），其中第$k$类样本所占比例为$p_k(k=1,2,…,|Y|)$，则其信息熵为：</p>
<script type="math/tex; mode=display">Ent(D)=-\sum_{k=1}^{|Y|} p_k ln p_k</script><p>$Ent(D)$的值越小，混乱程度越小，则$D$的纯度越高。</p>
<hr>
<p>了解了信息熵后，我们开始选择最优划分属性。假设我们当前选择离散属性$a_{i}$（这里先只讨论离散属性，连续属性后面会涉及）为判断依据，属性$a_i$共有Ⅴ可能的取值$\left\{  a^1,a^2,…,a^Ⅴ \right\}$，所以就会产生Ⅴ个分支结点$D^{v}$，然后我们分别计算$D^{v}$对应的熵值$Ent(D^v)$乘以相应的权重$|D^v|/|D|$求和，$\sum_{v=1}^{Ⅴ} \cfrac{|D^v|}{|D|} Ent(D^v)$即为划分后的熵值。</p>
<p>划分后的熵值肯定是会增大的，直观理解的话，根据某一属性划分后纯度提升了，划分前后熵值的差即为<strong>信息增益</strong>（information gain）</p>
<script type="math/tex; mode=display">Gain(D,a_i)=Ent(D)-\sum_{v=1}^{Ⅴ} \cfrac{|D^v|}{|D|} Ent(D^v)</script><p>我们就依次计算每个划分属性$a_i（i=1,2,…,d）$的信息增益，选择其中信息增益最大的作为<strong>最优划分属性</strong>。</p>
<h4 id="3-2-增益率（C4-5决策树）"><a href="#3-2-增益率（C4-5决策树）" class="headerlink" title="3.2 增益率（C4.5决策树）"></a>3.2 增益率（C4.5决策树）</h4><p>事实上，信息增益对拥有<strong>更多</strong>可能取值的属性$a_i$有所偏好，我们不妨做一个极端的假设，假设我们将样本集$D=\left\{ (x_1,y_1),(x_2,y_2),…,(x_m,y_m)  \right\}$分为了m个分支结点，则$\sum_{v=1}^{Ⅴ} \cfrac{|D^v|}{|D|} Ent(D^v)=0$，那么相应的信息增益$Gain(D,a_i)=Ent(D)-\sum_{v=1}^{Ⅴ} \cfrac{|D^v|}{|D|} Ent(D^v)=Ent(D)$将达到最大，然后这样的决策树不具有泛化能力，无法对其他的新样本进行有效的预测。</p>
<p>所以<strong>C4.5决策树</strong>就没有采用信息增益，而是采用<strong>增益率</strong>（gain ratio），我们直接看其定义：</p>
<script type="math/tex; mode=display">\left\{ \begin{aligned} Gain \mbox{_} ratio(D,a_i)= \cfrac{Gain(D, a_i)}{Ⅳ(a_i)}\\ Ⅳ(a_i)=-\sum_{v=1}^{Ⅴ} \cfrac{|D^v|}{|D|} ln\cfrac{|D^v|}{|D|} \end{aligned} \right.</script><p>其中$ Ⅳ(a_i)$被称为属性$a_i$的“固有值”（intrinsic value），当属性$a_i$的可能取值$Ⅴ$越大，其$ Ⅳ(a_i)$也会越大，用信息增益除以固有值，从而消除对取值更多属性$a_i$的偏好，但是这种“消除有点过头了”，导致增益率对取值<strong>更少</strong>属性$a_i$的偏好。</p>
<p>所以C4.5决策树并不是直接使用的增益率，而是使用了一个启发式：在所有划分属性中找出<strong>信息增益高</strong>于平均水平的属性，然后再从中挑选<strong>增益率最高</strong>的。</p>
<h4 id="3-3-基尼指数（CART决策树）"><a href="#3-3-基尼指数（CART决策树）" class="headerlink" title="3.3 基尼指数（CART决策树）"></a>3.3 基尼指数（CART决策树）</h4><p>CART决策树是采用基尼指数来选用最优划分属性的，以下是基尼指数的定义（采用和3.1信息增益相同的数学符号，在此不重复声明）：</p>
<script type="math/tex; mode=display">Gini(D)=\sum_{k=1}^{|Y|}\sum_{k' \ne k} p_k p_{k'}=1-\sum_{k=1}^{|Y|} p_k^2</script><p>基尼指数直观反映了：随机从数据集中抽取两个样本，其类别不相同的概率。所以相应的基尼指数越小，其纯度也就越高。</p>
<p>同样的，当选择离散属性$a_{i}$为判断依据，属性$a_i$共有Ⅴ可能的取值$\left\{  a^1,a^2,…,a^Ⅴ \right\}$，产生Ⅴ个分支结点$D^{v}$，分别计算$D^{v}$对应的基尼指数乘以相应的权重$|D^v|/|D|$即可求的划分后的基尼指数</p>
<script type="math/tex; mode=display">Gini(D,a)=\sum_{v=1}^{Ⅴ} \cfrac{|D^v|}{|D|} Gini(D^v)</script><p>然后我们就只需要选取划分后基尼指数最小的属性$a_i= argmin_{1 \le i \le Ⅴ} Gini(D,a_i)$即可.</p>
<h3 id="4-拓展部分"><a href="#4-拓展部分" class="headerlink" title="4.拓展部分"></a>4.拓展部分</h3><h4 id="4-1-预剪枝"><a href="#4-1-预剪枝" class="headerlink" title="4.1 预剪枝"></a>4.1 预剪枝</h4><p>我们样本的属性可能非常多，如果我们严格按照上述决策树的递归生成过程会导致决策的分支过于庞大，从而导致<strong>过拟合</strong>，使得训练出来的模型泛化能力较差，所以我们就需要进行一些剪枝处理，减小整个决策树的决策分支。</p>
<p>我们首先将样本集分为<strong>训练集</strong>和<strong>验证集</strong></p>
<p>对于预剪枝来说，就是在训练集上每次<strong>生成一个新的决策分支</strong>时（即递归生成决策树伪代码的第14行），就使用计算验证集代入计算相应的准确率，就会出现两种情况：① 生成新的决策分支导致准确率下降了，那么就能停止这次划分；② 生成新的决策分支导致准确率上升了，那么就能执行这次划分。可以参照下面这张西瓜书上的图对比一下（具体的数据duck不必在意）。</p>
<p><img src="https://s1.ax1x.com/2020/07/11/UMHj0S.png" alt="UMHj0S.png"></p>
<p><strong>优点</strong>：</p>
<ol>
<li>防止过拟合</li>
<li>及时剪枝，中止继续递归操作，在一定程度上加快了训练速度</li>
</ol>
<p><strong>缺点</strong>：</p>
<ol>
<li>也许验证集在划分后的准确率不如划分前的准确率，但是有可能划分后的<strong>后续划分</strong>可能会导致准确率的显著上升，所以预剪枝存在<strong>欠拟合</strong>的风险。</li>
</ol>
<h4 id="4-2-后剪枝"><a href="#4-2-后剪枝" class="headerlink" title="4.2 后剪枝"></a>4.2 后剪枝</h4><p>后剪枝的操作和预剪枝其实非常相似。后剪枝是在通过决策树生成的递归算法生成一颗完全的决策树后，然后自底向上，可以按照<strong>后根遍历</strong>的顺序尝试删除结点，比较去除前后的<strong>验证集准确率</strong>，如果能够提高准确率，则去除相应的划分。</p>
<p>下面是从西瓜书上截取的一个样例</p>
<p><a href="https://imgchr.com/i/UMqFCd" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2020/07/11/UMqFCd.png" alt="UMqFCd.png"></a></p>
<p><strong>优点</strong>：</p>
<ol>
<li>使用后剪枝之前，所有分支都已展开，所以不用担心<strong>欠拟合</strong></li>
<li>防止过拟合（进行了剪枝操作）</li>
</ol>
<p><strong>缺点</strong>：</p>
<ol>
<li>需要展开所有分支，所以生成决策树耗费时间会更多</li>
</ol>
<h4 id="4-3-连续值处理"><a href="#4-3-连续值处理" class="headerlink" title="4.3 连续值处理"></a>4.3 连续值处理</h4><p>前面我们提到的属性的划分都是对于离散属性而言的，然而还有一些属性不是离散的值（比如西瓜的重量、含糖量等），将连续值离散化最简单的就是采用<strong>二分法</strong>。</p>
<p>对于样本集$D$上的连续属性$a_i$，假设有$n$个取值，从小到大排序为$\left\{  a_i^1 , a_i^1 , … , a_i^n \right\}$，然后尝试在相邻的两点取中位数尝试划分，即所有可能划分点为$T_n = \left\{  \cfrac{a^j_i + a^{j+1}_i}{2} | 1 \le j \le n-1 \right\}$</p>
<p>然在计算所有划分点对应的信息增益（或是增益率、基尼指数），求出连续属性$a_i$的<strong>最佳划分点</strong>，然后再和其他的划分属性进行对比，然后再决定此次划分属性。</p>
<p><strong>值得注意</strong>的是，与离散属性不同，连续属性可以多次作为划分属性（其实每次划分只使用了其<strong>一个划分中位点</strong>）。</p>
<h4 id="4-4-缺失值处理"><a href="#4-4-缺失值处理" class="headerlink" title="4.4 缺失值处理"></a>4.4 缺失值处理</h4><p>我们的数据集中可能存在缺失值，缺失值的处理相较于连续值会麻烦一点。</p>
<p>我们需要为每个样本$x$定义权重$w_x$（权重$w_s$初始值为1），对于样本集D和含有缺失值的划分属性$a_i$，设$\overline{D}$为$D$中属性$a_i$不是缺失值的样本集合，则可以计算下列值：</p>
<script type="math/tex; mode=display">\left\{ \begin{aligned} \rho = \cfrac{\sum_{x \in \overline{D} } w_x } {\sum_{x \in D } w_x} \,\mbox{（即不是缺失值的比例）} \,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\,\ \\ p_k =  \cfrac{\sum_{x \in \overline{D_k} } w_x } {\sum_{x \in \overline{D} } w_x} \,\mbox{(即在}\overline{D}\mbox{中为k类样本的比例,} 1\le k \le |Y|) \\ r_v =  \cfrac{\sum_{x \in \overline{D^v} } w_x } {\sum_{x \in \overline{D} } w_x} \,\mbox{(即在}\overline{D}\mbox{中为属性为} a^v \mbox{的比例,} 1\le r \le |Ⅴ|) \end{aligned} \right.</script><p>不难发现，$\sum_{k=1}^{|Y|} p_k =1 ,\sum_{v=1}^{|Y|} r_v =1$，并且当权重$w_x$初始值为1时，$p_k,r_v$和之前的定义没有什么区别。</p>
<p>然后使用上述公式得出$p_k , r_v$，进而计算相应的信息增益（或是增益率、基尼指数），然后将求得的信息增益乘以$ \rho $得到该划分属性最终的信息增益，再和其他划分属性进行对于，得到最终的划分属性。</p>
<p>如果很<strong>不幸</strong>，该含有缺失值的划分属性$a_i$被选为了最优划分属性，① 那么对于不是缺失值的样本$x$保持其权重$w_x$直接划入相应子节点，② 但是对于属性$a_i$为缺失值的样本$x$，将其划分到<strong>所有的子节点</strong>，但是其权重子节点中调整为$r_v\times w_x$，直观理解就，就是让一个样本以不同的概率划分到不同的子结点中。</p>
<p><strong>进行预测时，碰到缺失值怎么办？</strong>这是我们就选择该结点下$r_v$最大的一个分支（即该属性的取值最多）。</p>
<h4 id="4-5-多变量决策树"><a href="#4-5-多变量决策树" class="headerlink" title="4.5 多变量决策树"></a>4.5 多变量决策树</h4><p>如果我们将属性看作是坐标空间的坐标轴，那么样本$x$的属性$\left\{  a^1,a^2,…,a^Ⅴ \right\}$就是其相应的坐标，决策树的分类其实就是在这个坐标空间中画出了一个<strong>分类边界</strong>。</p>
<p>我们以两个属性为例查看其决策边界（图片采用自西瓜书）</p>
<p><img src="https://s1.ax1x.com/2020/07/11/UMOwcR.png" alt="UMOwcR.png"></p>
<p>可以看到分类边界的每一段都是和坐标轴平行的，当分类边界比较复杂时，就需要多段划分才能获得较好的划分效果。</p>
<p>但是我们是否一定要使用这样平行与坐标轴的边界吗？当然不是，当我们使用多个属性<strong>线性组合</strong>就能得到倾斜的决策边界，如下图（采用自西瓜书）</p>
<p><img src="https://s1.ax1x.com/2020/07/11/UMOrB6.png" alt="UMOrB6.png"></p>
<p>更进一步想的话，我们是否一定要使用”平直“的决策边界？其实也不是，我们不一定使用的是多个属性的线性组合，当然也能使用非线性组合，然后就能得到如下图所示的效果（来自西瓜书）。</p>
<p><img src="https://s1.ax1x.com/2020/07/11/UMOcND.png" alt="UMOcND.png"></p>
<p>当然这里多变量决策树了解的比较浅显，具体要如何构建多变量决策树？这是一个问题，有缘再了解吧~</p>
<h2 id="CART决策树实践"><a href="#CART决策树实践" class="headerlink" title="CART决策树实践"></a>CART决策树实践</h2><p>ID3、C4.5、CART决策树实现过程大体相同，只需更改其中的最优划分属性算法即可（相较于决策树的其它实现步骤是相对来说比较简单的），所以这里就只实践了CART决策树。需要完整代码和数据的可以点击这里：<a href="https://github.com/AgentGuo/decision_tree" target="_blank" rel="noopener">点我</a>，这次实践主要就是不使用任何机器学习库，纯手工完成的<strong>决策树的搭建</strong>，并且完成了<strong>后剪枝操作</strong></p>
<p>python3开发环境说明：</p>
<ul>
<li><code>csv</code>:<code>1.0</code></li>
</ul>
<h3 id="1-数据加载"><a href="#1-数据加载" class="headerlink" title="1. 数据加载"></a>1. 数据加载</h3><p>采用的是Kaggle上的Titanic数据集（<a href="https://www.kaggle.com/c/titanic" target="_blank" rel="noopener">点击这里</a>），RMS泰坦尼克号的沉没是历史上最臭名昭着的沉船之一，2224名乘客和机组人员中有1502人遇难，一个人是否能够存活下来与许多的因素有关，题目给出了一个训练数据集（train.csv）、一个需要预测的数据集（test.csv）和一个提交的模板（gender_submission.csv）。我们着重分析一下已知结果的<strong>训练数据集</strong>。</p>
<p>其中包含了11个特征，除去没有直接帮助的姓名特征和票号特征还剩9个特征，如下图所示（最后一项为权重，用于缺失值处理），我们将数据加载进来，按照下图的映射关系，将csv表格中的数据转化为int或float类型。</p>
<p><img src="https://s1.ax1x.com/2020/07/12/U1yZXd.png" alt="U1yZXd.png"></p>
<p>值得注意的是：</p>
<ol>
<li>船舱等级整体减1（便于写代码）</li>
<li>原本有三项特征有缺失值，但是经过分析后，船舱特征是否缺失和乘客是否存活有一定关系，所以将它的缺失与不缺失直接转化为特征值</li>
<li>兄弟姐妹配偶数量和父母子女数量大部分乘客都是0，少部分小于等于2，极少部分大于2，所以将多个离散值映射到了0~2</li>
</ol>
<p>加载部分代码（按照大于 5:1 划分训练集和验证集）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadTrainData</span><span class="params">(filename)</span>:</span></span><br><span class="line">    data = []</span><br><span class="line">    f = list(csv.reader(open(filename, <span class="string">'r'</span>)))[<span class="number">1</span>:]   <span class="comment"># 读取去掉表头的部分</span></span><br><span class="line">    embarkedDist = &#123;<span class="string">'C'</span>:<span class="number">1</span>, <span class="string">'Q'</span>:<span class="number">2</span>, <span class="string">'S'</span>:<span class="number">3</span>&#125;    <span class="comment"># 无缺失值时，'C':1, 'Q':2, 'S':3</span></span><br><span class="line">    sibspParch = [<span class="number">1</span>, <span class="number">2</span>]</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">        <span class="keyword">if</span> int(line[<span class="number">6</span>]) == <span class="number">0</span>:  <span class="comment"># 转化sibsp</span></span><br><span class="line">            sibsp = <span class="number">0</span></span><br><span class="line">        <span class="keyword">elif</span> int(line[<span class="number">6</span>]) &lt;= <span class="number">2</span>:</span><br><span class="line">            sibsp = <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            sibsp = <span class="number">2</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> int(line[<span class="number">7</span>]) == <span class="number">0</span>:   <span class="comment"># 转化sibsp</span></span><br><span class="line">            parch = <span class="number">0</span></span><br><span class="line">        <span class="keyword">elif</span> int(line[<span class="number">7</span>]) &lt;= <span class="number">2</span>:</span><br><span class="line">            parch = <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            parch = <span class="number">2</span></span><br><span class="line">        dataDist=&#123;<span class="string">'survived'</span>:int(line[<span class="number">1</span>]),</span><br><span class="line">             <span class="string">'pclass'</span>: int(line[<span class="number">2</span>]) - <span class="number">1</span>,</span><br><span class="line">             <span class="string">'sex'</span>: <span class="number">0</span> <span class="keyword">if</span> line[<span class="number">4</span>] == <span class="string">'male'</span> <span class="keyword">else</span> <span class="number">1</span>,   <span class="comment"># male:0  female:1</span></span><br><span class="line">             <span class="string">'age'</span>: <span class="number">0</span> <span class="keyword">if</span> len(line[<span class="number">5</span>]) == <span class="number">0</span> <span class="keyword">else</span> float(line[<span class="number">5</span>]),   <span class="comment"># 有缺失值保存为0</span></span><br><span class="line">             <span class="string">'sibsp'</span>: sibsp,</span><br><span class="line">             <span class="string">'parch'</span>: parch,</span><br><span class="line">             <span class="string">'fare'</span>: float(line[<span class="number">9</span>]),</span><br><span class="line">             <span class="string">'cabin'</span>: <span class="number">0</span> <span class="keyword">if</span> len(line[<span class="number">10</span>]) == <span class="number">0</span> <span class="keyword">else</span> <span class="number">1</span>,   <span class="comment"># 有缺失值：0  无缺失值：1</span></span><br><span class="line">             <span class="string">'embarked'</span>: <span class="number">0</span> <span class="keyword">if</span> len(line[<span class="number">11</span>]) == <span class="number">0</span> <span class="keyword">else</span> embarkedDist[line[<span class="number">11</span>]],   <span class="comment"># 有缺失值：0  无缺失值保存为1、2、3</span></span><br><span class="line">                  <span class="string">'w'</span>: <span class="number">1</span>&#125;  <span class="comment"># 初始化权重</span></span><br><span class="line">        data.append(dataDist)</span><br><span class="line">    random.shuffle(data)     <span class="comment"># 将加载好的数据打乱</span></span><br><span class="line">    trainData = data[:<span class="number">741</span>]  <span class="comment"># 按大致5:1划分训练集和验证集</span></span><br><span class="line">    devData = data[<span class="number">741</span>:]</span><br><span class="line">    <span class="keyword">return</span> trainData, devData</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">trainData, devData = loadTrainData(<span class="string">'train.csv'</span>)</span><br><span class="line">print(len(trainData), len(devData), trainData[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">741 150 &#123;&#39;survived&#39;: 0, &#39;pclass&#39;: 0, &#39;sex&#39;: 0, &#39;age&#39;: 19.0, &#39;sibsp&#39;: 2, &#39;parch&#39;: 1, &#39;fare&#39;: 263.0, &#39;cabin&#39;: 1, &#39;embarked&#39;: 3, &#39;w&#39;: 1&#125;</span><br></pre></td></tr></table></figure>
<h3 id="2-构建决策树"><a href="#2-构建决策树" class="headerlink" title="2. 构建决策树"></a>2. 构建决策树</h3><p>决策树的定义比较繁琐，由于许多划分属性的取值并不是只有两种取值，从而形成的决策树不会是一颗二叉树，所以这里的决策树是采用列表存储的孩子结点（之所以能用列表还不需要字典，是因为将属性值都转化为了<code>[0,i]</code>的离散值（连续值就两种情况，小于和大于），不知所云也没关系，直接看代码也能看懂）</p>
<h4 id="2-1-结点定义"><a href="#2-1-结点定义" class="headerlink" title="2.1 结点定义"></a>2.1 结点定义</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Node</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,attribute)</span>:</span></span><br><span class="line">        self.son = []  <span class="comment"># 结点的孩子</span></span><br><span class="line">        self.attribute = attribute    <span class="comment"># 结点当前的划分属性</span></span><br><span class="line">        self.boundary = <span class="number">-1</span>  <span class="comment"># 当前结点划分属性为连续值时才修改该属性</span></span><br><span class="line">        self.kind = <span class="number">-1</span>    <span class="comment"># 当前结点的种类，只有当时叶子结点时用于判定</span></span><br><span class="line">        self.leaf = <span class="number">0</span>    <span class="comment"># 当前结点为叶子结点时指定为1</span></span><br><span class="line">        self.prior = <span class="number">0</span>  <span class="comment"># 当进行决策时出现缺失值，优先选择的种类</span></span><br></pre></td></tr></table></figure>
<h4 id="2-2-决策树定义"><a href="#2-2-决策树定义" class="headerlink" title="2.2 决策树定义"></a>2.2 决策树定义</h4><p>这一部分代码会比较冗长，奈何本人水平有限，但是都是做了非常详细的注释，不用一次性都将所有函数读完，用到了再回头看即可。</p>
<p><strong>决策树的构造函数</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">decisionTree</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.root = Node(<span class="string">''</span>)</span><br></pre></td></tr></table></figure>
<p><strong>递归构建决策树</strong>：由于特征种类的复杂性，所已对不同特征进行了不同的操作，因而代码显得比较冗长</p>
<p>递归设置了三个出口（在理论部分已经强调过了），还有就是涉及到了缺失值和连续值的处理，可以参考前文的理论部分分析。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createTree</span><span class="params">(self, attributes, datas)</span>:</span> <span class="comment"># 当前可用属性，当前可用样本，当前所在的递归层数（即在第几层结点）</span></span><br><span class="line">    node = Node(<span class="string">''</span>)</span><br><span class="line">    node.kind = self.getKind(datas)</span><br><span class="line">    sameFlag = <span class="number">1</span>    <span class="comment"># 标记当前样本种类是否相同</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, len(datas)):</span><br><span class="line">        <span class="keyword">if</span> datas[i][<span class="string">'survived'</span>] != datas[<span class="number">0</span>][<span class="string">'survived'</span>]:</span><br><span class="line">            sameFlag = <span class="number">0</span></span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">if</span> sameFlag == <span class="number">1</span>:        <span class="comment"># 递归出口①：当样本属于同一类别</span></span><br><span class="line">        node.leaf = <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> node</span><br><span class="line">    </span><br><span class="line">    delAttributes = []   <span class="comment"># 需要删除的无效划分属性</span></span><br><span class="line">    <span class="keyword">for</span> a <span class="keyword">in</span> attributes:</span><br><span class="line">        <span class="keyword">if</span> a == <span class="string">'pclass'</span> <span class="keyword">or</span> a == <span class="string">'sibsp'</span> <span class="keyword">or</span> a == <span class="string">'parch'</span>:</span><br><span class="line">            effectiveAttribute = [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]   <span class="comment"># 标记当前属性是否为有效属性</span></span><br><span class="line">            <span class="keyword">for</span> data <span class="keyword">in</span> datas:</span><br><span class="line">                effectiveAttribute[data[a]] = <span class="number">1</span>   <span class="comment"># 说明该属性有样本</span></span><br><span class="line">            <span class="keyword">if</span> effectiveAttribute[<span class="number">0</span>] * effectiveAttribute[<span class="number">1</span>] * effectiveAttribute[<span class="number">2</span>] == <span class="number">0</span>:  <span class="comment"># 当该属性的有一个取值无样本，则删除该属性</span></span><br><span class="line">                delAttributes.append(a)</span><br><span class="line">        <span class="keyword">elif</span> a == <span class="string">'sex'</span> <span class="keyword">or</span> a == <span class="string">'cabin'</span>:</span><br><span class="line">            effectiveAttribute = [<span class="number">0</span>, <span class="number">0</span>]   <span class="comment"># 标记当前属性是否为有效属性</span></span><br><span class="line">            <span class="keyword">for</span> data <span class="keyword">in</span> datas:</span><br><span class="line">                effectiveAttribute[data[a]] = <span class="number">1</span>   <span class="comment"># 说明该属性有样本</span></span><br><span class="line">            <span class="keyword">if</span> effectiveAttribute[<span class="number">0</span>] * effectiveAttribute[<span class="number">1</span>]== <span class="number">0</span>:  <span class="comment"># 当该属性的有一个取值无样本，则删除该属性</span></span><br><span class="line">                delAttributes.append(a)</span><br><span class="line">        <span class="keyword">elif</span> a == <span class="string">'embarked'</span>:</span><br><span class="line">            effectiveAttribute = [<span class="number">0</span> , <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]   <span class="comment"># 标记当前属性是否为有效属性</span></span><br><span class="line">            <span class="keyword">for</span> data <span class="keyword">in</span> datas:</span><br><span class="line">                effectiveAttribute[data[a]] = <span class="number">1</span>   <span class="comment"># 说明该属性有样本</span></span><br><span class="line">            <span class="keyword">if</span> effectiveAttribute[<span class="number">1</span>] * effectiveAttribute[<span class="number">2</span>] * effectiveAttribute[<span class="number">3</span>] == <span class="number">0</span>:  <span class="comment"># 当该属性的有一个取值无样本，则删除该属性</span></span><br><span class="line">                delAttributes.append(a)                           <span class="comment"># 不记录缺失值</span></span><br><span class="line">    <span class="keyword">for</span> a <span class="keyword">in</span> delAttributes:   <span class="comment"># 从属性列表中删除无效属性</span></span><br><span class="line">        attributes.remove(a)</span><br><span class="line">    <span class="keyword">if</span> len(attributes) == <span class="number">0</span>:   <span class="comment"># 递归出口②：如果此时无有效属性</span></span><br><span class="line">        node.leaf = <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> node</span><br><span class="line">    </span><br><span class="line">    gini, a, boundary = self.Gini(attributes, datas)</span><br><span class="line">    node.attribute = a  <span class="comment"># 当前结点使用的划分属性</span></span><br><span class="line">    attributes.remove(a)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> a == <span class="string">'pclass'</span> <span class="keyword">or</span> a == <span class="string">'sibsp'</span> <span class="keyword">or</span> a == <span class="string">'parch'</span>:</span><br><span class="line">        datasSub = [[],[],[]]  <span class="comment"># 保存用于划分的子集</span></span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> datas:</span><br><span class="line">            datasSub[data[a]].append(deepcopy(data))  <span class="comment"># 子集添加元素</span></span><br><span class="line">        <span class="keyword">if</span> len(datasSub[<span class="number">0</span>]) == <span class="number">0</span> <span class="keyword">or</span> len(datasSub[<span class="number">1</span>]) == <span class="number">0</span> <span class="keyword">or</span> len(datasSub[<span class="number">2</span>]) == <span class="number">0</span>:   <span class="comment"># 递归出口③：有一个划分样本集合为空，停止划分</span></span><br><span class="line">            node.leaf = <span class="number">1</span></span><br><span class="line">            <span class="keyword">return</span> node</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):  <span class="comment"># 若集合都不为空，则继续递归划分</span></span><br><span class="line">            node.son.append(self.createTree(deepcopy(attributes), datasSub[i]))</span><br><span class="line">        <span class="keyword">return</span> node</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">elif</span> a == <span class="string">'sex'</span> <span class="keyword">or</span> a == <span class="string">'cabin'</span>:</span><br><span class="line">        datasSub = [[],[]]  <span class="comment"># 保存用于划分的子集</span></span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> datas:</span><br><span class="line">            datasSub[data[a]].append(deepcopy(data))  <span class="comment"># 子集添加元素</span></span><br><span class="line">        <span class="keyword">if</span> len(datasSub[<span class="number">0</span>]) == <span class="number">0</span> <span class="keyword">or</span> len(datasSub[<span class="number">1</span>]) == <span class="number">0</span> :   <span class="comment"># 递归出口③：有一个划分样本集合为空，停止划分</span></span><br><span class="line">            node.leaf = <span class="number">1</span></span><br><span class="line">            <span class="keyword">return</span> node</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2</span>):  <span class="comment"># 若集合都不为空，则继续递归划分</span></span><br><span class="line">            node.son.append(self.createTree(deepcopy(attributes), datasSub[i]))</span><br><span class="line">        <span class="keyword">return</span> node</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">elif</span> a == <span class="string">'fare'</span>:</span><br><span class="line">        node.boundary = boundary  <span class="comment"># 由于是连续值，需要调整</span></span><br><span class="line">        datasSub = [[],[]]</span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> datas:</span><br><span class="line">            <span class="keyword">if</span> data[a] &lt; boundary:</span><br><span class="line">                datasSub[<span class="number">0</span>].append(deepcopy(data))   <span class="comment"># 添加相应的权重</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                datasSub[<span class="number">1</span>].append(deepcopy(data))   <span class="comment"># 添加相应的权重</span></span><br><span class="line">        <span class="keyword">if</span> len(datasSub[<span class="number">0</span>]) == <span class="number">0</span> <span class="keyword">or</span> len(datasSub[<span class="number">1</span>]) == <span class="number">0</span> :   <span class="comment"># 递归出口③：有一个划分样本集合为空，停止划分</span></span><br><span class="line">            node.leaf = <span class="number">1</span></span><br><span class="line">            <span class="keyword">return</span> node</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2</span>):  <span class="comment"># 若集合都不为空，则继续递归划分</span></span><br><span class="line">            node.son.append(self.createTree(deepcopy(attributes), datasSub[i]))</span><br><span class="line">        <span class="keyword">return</span> node</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">elif</span> a == <span class="string">'embarked'</span>:</span><br><span class="line">        datasSub = [[],[],[]]  <span class="comment"># 保存用于划分的子集</span></span><br><span class="line">        missData = []  <span class="comment"># 保存缺失值</span></span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> datas:</span><br><span class="line">            <span class="keyword">if</span> data[a] != <span class="number">0</span>:</span><br><span class="line">                datasSub[data[a] - <span class="number">1</span>].append(deepcopy(data))  <span class="comment"># 子集添加元素</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                missData.append(deepcopy(data))  <span class="comment"># 添加缺失值</span></span><br><span class="line">        length = []</span><br><span class="line">        length.append(len(datasSub[<span class="number">0</span>]))  <span class="comment"># 记录各个集合的大小，用于后续计算</span></span><br><span class="line">        length.append(len(datasSub[<span class="number">1</span>]))</span><br><span class="line">        length.append(len(datasSub[<span class="number">2</span>]))</span><br><span class="line">        lenSum = sum(length)</span><br><span class="line">        lenMax = max(length)</span><br><span class="line">        <span class="keyword">if</span> length[<span class="number">0</span>] * length[<span class="number">1</span>] * length[<span class="number">2</span>] == <span class="number">0</span>:   <span class="comment"># 递归出口③：有一个划分样本集合为空，停止划分</span></span><br><span class="line">            node.leaf = <span class="number">1</span></span><br><span class="line">            <span class="keyword">return</span> node</span><br><span class="line">        <span class="keyword">if</span> lenMax == length[<span class="number">0</span>]:  <span class="comment"># 由于embarked属性有可能出现缺失值，所有要设置优先属性</span></span><br><span class="line">            node.prior = <span class="number">0</span></span><br><span class="line">        <span class="keyword">elif</span> lenMax == length[<span class="number">1</span>]:</span><br><span class="line">            node.prior = <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            node.prior = <span class="number">2</span></span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> missData:  <span class="comment"># 将缺失值调整权重加入到各个集合</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">                temp = deepcopy(data)</span><br><span class="line">                temp[<span class="string">'w'</span>] *= length[i]/lenSum   <span class="comment"># 修改权重</span></span><br><span class="line">                datasSub[i].append(temp)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):  <span class="comment"># 若集合都不为空，则继续递归划分</span></span><br><span class="line">            node.son.append(self.createTree(deepcopy(attributes), datasSub[i]))</span><br><span class="line">        <span class="keyword">return</span> node</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">elif</span> a == <span class="string">'age'</span>:</span><br><span class="line">        node.boundary = boundary</span><br><span class="line">        datasSub = [[],[]]</span><br><span class="line">        missData = []  <span class="comment"># 保存缺失值</span></span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> datas:</span><br><span class="line">            <span class="keyword">if</span> data[a] != <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">if</span> data[a] &lt; boundary:</span><br><span class="line">                    datasSub[<span class="number">0</span>].append(deepcopy(data))   <span class="comment"># 添加相应的权重</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    datasSub[<span class="number">1</span>].append(deepcopy(data))   <span class="comment"># 添加相应的权重</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                missData.append(deepcopy(data))  <span class="comment"># 添加缺失值</span></span><br><span class="line">        length = []</span><br><span class="line">        length.append(len(datasSub[<span class="number">0</span>]))  <span class="comment"># 记录各个集合的大小，用于后续计算</span></span><br><span class="line">        length.append(len(datasSub[<span class="number">1</span>]))</span><br><span class="line">        lenSum = sum(length)</span><br><span class="line">        lenMax = max(length)</span><br><span class="line">        <span class="keyword">if</span> len(datasSub[<span class="number">0</span>]) == <span class="number">0</span> <span class="keyword">or</span> len(datasSub[<span class="number">1</span>]) == <span class="number">0</span> :   <span class="comment"># 递归出口③：有一个划分样本集合为空，停止划分</span></span><br><span class="line">            node.leaf = <span class="number">1</span></span><br><span class="line">            <span class="keyword">return</span> node</span><br><span class="line">        <span class="keyword">if</span> lenMax == length[<span class="number">0</span>]:  <span class="comment"># 由于embarked属性有可能出现缺失值，所有要设置优先属性</span></span><br><span class="line">            node.prior = <span class="number">0</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            node.prior = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> missData:  <span class="comment"># 将缺失值调整权重加入到各个集合</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2</span>):</span><br><span class="line">                temp = deepcopy(data)</span><br><span class="line">                temp[<span class="string">'w'</span>] *= length[i]/lenSum   <span class="comment"># 修改权重</span></span><br><span class="line">                datasSub[i].append(temp)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2</span>):  <span class="comment"># 若集合都不为空，则继续递归划分</span></span><br><span class="line">            node.son.append(self.createTree(deepcopy(attributes), datasSub[i]))</span><br><span class="line">        <span class="keyword">return</span> node</span><br></pre></td></tr></table></figure>
<p><strong>获取当前样本集中最多的种类</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getKind</span><span class="params">(self, datas)</span>:</span></span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> datas:</span><br><span class="line">        count += data[<span class="string">'survived'</span>]</span><br><span class="line">    <span class="keyword">if</span> count &gt; len(datas)//<span class="number">2</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br></pre></td></tr></table></figure>
<p><strong>计算Gini指数</strong>：也是由于特征的复杂性，所以不同特征计算Gini指数会有一些差异，需要分情况讨论，所以代码显得很冗长（但是写得都很浅显   是我菜哈哈哈）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Gini</span><span class="params">(self, attributes, datas)</span>:</span></span><br><span class="line">    giniList = []</span><br><span class="line">    <span class="keyword">for</span> a <span class="keyword">in</span> attributes:</span><br><span class="line">        <span class="keyword">if</span> a == <span class="string">'pclass'</span> <span class="keyword">or</span> a == <span class="string">'sibsp'</span> <span class="keyword">or</span> a == <span class="string">'parch'</span>:  <span class="comment"># 这三类相似，离散属性都是三种取值</span></span><br><span class="line">            count=[[<span class="number">0</span>,<span class="number">0</span>], [<span class="number">0</span>,<span class="number">0</span>], [<span class="number">0</span>,<span class="number">0</span>]]   <span class="comment"># 用于保存该属性下存活于死亡的情况</span></span><br><span class="line">            <span class="keyword">for</span> data <span class="keyword">in</span> datas:</span><br><span class="line">                count[data[a]][data[<span class="string">'survived'</span>]] += data[<span class="string">'w'</span>]   <span class="comment"># 添加相应的权重</span></span><br><span class="line">            gini = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):  <span class="comment"># 计算基尼指数</span></span><br><span class="line">                gini += (count[i][<span class="number">0</span>] + count[i][<span class="number">1</span>])/len(datas) * (<span class="number">1</span> - (count[i][<span class="number">1</span>]/(count[i][<span class="number">0</span>] + count[i][<span class="number">1</span>]))**<span class="number">2</span>)</span><br><span class="line">            giniList.append(gini)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">elif</span> a == <span class="string">'sex'</span> <span class="keyword">or</span> a == <span class="string">'cabin'</span>:  <span class="comment"># 这两类相似，离散数学都是两种取值</span></span><br><span class="line">            count=[[<span class="number">0</span>,<span class="number">0</span>], [<span class="number">0</span>,<span class="number">0</span>]]    <span class="comment"># 用于保存该属性下存活于死亡的情况</span></span><br><span class="line">            <span class="keyword">for</span> data <span class="keyword">in</span> datas:</span><br><span class="line">                count[data[a]][data[<span class="string">'survived'</span>]] += data[<span class="string">'w'</span>]   <span class="comment"># 添加相应的权重</span></span><br><span class="line">            gini = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2</span>):  <span class="comment"># 计算基尼指数</span></span><br><span class="line">                gini += (count[i][<span class="number">0</span>] + count[i][<span class="number">1</span>])/len(datas) * (<span class="number">1</span> - (count[i][<span class="number">1</span>]/(count[i][<span class="number">0</span>] + count[i][<span class="number">1</span>]))**<span class="number">2</span>)</span><br><span class="line">            giniList.append(gini)</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">elif</span> a == <span class="string">'fare'</span>:</span><br><span class="line">            fareList = []</span><br><span class="line">            <span class="keyword">for</span> data <span class="keyword">in</span> datas:</span><br><span class="line">                fareList.append(data[<span class="string">'fare'</span>])   <span class="comment"># 添加所有的fare</span></span><br><span class="line">            fareList = list(set(fareList))   <span class="comment"># 去重</span></span><br><span class="line">            fareList.sort()</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(len(fareList) - <span class="number">1</span>):</span><br><span class="line">                fareList[i] = (fareList[i] + fareList[i+<span class="number">1</span>])/<span class="number">2</span>   <span class="comment"># 计算所有可能的中位值</span></span><br><span class="line">            fareList.pop()</span><br><span class="line">            gini_temp = []  <span class="comment"># 暂存所有的gini指数</span></span><br><span class="line">            <span class="keyword">for</span> fare <span class="keyword">in</span> fareList:</span><br><span class="line">                count=[[<span class="number">0</span>,<span class="number">0</span>], [<span class="number">0</span>,<span class="number">0</span>]]</span><br><span class="line">                <span class="keyword">for</span> data <span class="keyword">in</span> datas:</span><br><span class="line">                    <span class="keyword">if</span> data[<span class="string">'fare'</span>] &lt; fare:</span><br><span class="line">                        count[<span class="number">0</span>][data[<span class="string">'survived'</span>]] += data[<span class="string">'w'</span>]   <span class="comment"># 添加相应的权重</span></span><br><span class="line">                    <span class="keyword">else</span>:</span><br><span class="line">                        count[<span class="number">1</span>][data[<span class="string">'survived'</span>]] += data[<span class="string">'w'</span>]   <span class="comment"># 添加相应的权重</span></span><br><span class="line">                gini = <span class="number">0</span></span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2</span>):  <span class="comment"># 计算基尼指数</span></span><br><span class="line">                    gini += (count[i][<span class="number">0</span>] + count[i][<span class="number">1</span>])/len(datas) * (<span class="number">1</span> - (count[i][<span class="number">1</span>]/(count[i][<span class="number">0</span>] + count[i][<span class="number">1</span>]))**<span class="number">2</span>)</span><br><span class="line">                gini_temp.append(gini)</span><br><span class="line">            gini = min(gini_temp)   <span class="comment"># 求出最小的基尼指数</span></span><br><span class="line">            fare = fareList[gini_temp.index(gini)]   <span class="comment"># 求出最小基尼指数相应的划分fare</span></span><br><span class="line">            giniList.append(gini)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">elif</span> a == <span class="string">'embarked'</span>:</span><br><span class="line">            count=[[<span class="number">0</span>,<span class="number">0</span>], [<span class="number">0</span>,<span class="number">0</span>], [<span class="number">0</span>,<span class="number">0</span>]]   <span class="comment"># 用于保存该属性下存活于死亡的情况</span></span><br><span class="line">            dataNum = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> data <span class="keyword">in</span> datas:</span><br><span class="line">                <span class="keyword">if</span> data[<span class="string">'embarked'</span>] != <span class="number">0</span>:  <span class="comment"># 不是缺失值情况</span></span><br><span class="line">                    count[data[<span class="string">'embarked'</span>] - <span class="number">1</span>][data[<span class="string">'survived'</span>]] += data[<span class="string">'w'</span>]   <span class="comment"># 添加相应的权重</span></span><br><span class="line">                    dataNum += <span class="number">1</span>  <span class="comment"># 非缺失值加1</span></span><br><span class="line">            rho = dataNum/len(datas)</span><br><span class="line">            gini = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):  <span class="comment"># 计算基尼指数</span></span><br><span class="line">                gini += (count[i][<span class="number">0</span>] + count[i][<span class="number">1</span>])/len(datas) * (<span class="number">1</span> - (count[i][<span class="number">1</span>]/(count[i][<span class="number">0</span>] + count[i][<span class="number">1</span>]))**<span class="number">2</span>)</span><br><span class="line">            gini *= rho   <span class="comment"># 乘以rho</span></span><br><span class="line">            giniList.append(gini)</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">elif</span> a == <span class="string">'age'</span>:</span><br><span class="line">            ageList = []</span><br><span class="line">            <span class="keyword">for</span> data <span class="keyword">in</span> datas:</span><br><span class="line">                <span class="keyword">if</span> data[<span class="string">'age'</span>] != <span class="number">0</span>:  <span class="comment"># 当不是缺失值时</span></span><br><span class="line">                    ageList.append(data[<span class="string">'age'</span>])   <span class="comment"># 添加所有的age</span></span><br><span class="line">            ageNum = len(ageList)</span><br><span class="line">            rho = ageNum/len(datas)</span><br><span class="line">            ageList = list(set(ageList))   <span class="comment"># 去重</span></span><br><span class="line">            ageList.sort()</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> range(len(ageList) - <span class="number">1</span>):</span><br><span class="line">                ageList[i] = (ageList[i] + ageList[i+<span class="number">1</span>])/<span class="number">2</span>   <span class="comment"># 计算所有可能的中位值</span></span><br><span class="line">            ageList.pop()</span><br><span class="line">            gini_temp = []  <span class="comment"># 暂存所有的gini指数</span></span><br><span class="line">            <span class="keyword">for</span> age <span class="keyword">in</span> ageList:</span><br><span class="line">                count=[[<span class="number">0</span>,<span class="number">0</span>], [<span class="number">0</span>,<span class="number">0</span>]]</span><br><span class="line">                <span class="keyword">for</span> data <span class="keyword">in</span> datas:</span><br><span class="line">                    <span class="keyword">if</span> data[<span class="string">'age'</span>] != <span class="number">0</span>:</span><br><span class="line">                        <span class="keyword">if</span> data[<span class="string">'age'</span>] &lt; age:</span><br><span class="line">                            count[<span class="number">0</span>][data[<span class="string">'survived'</span>]] += data[<span class="string">'w'</span>]   <span class="comment"># 添加相应的权重</span></span><br><span class="line">                        <span class="keyword">else</span>:</span><br><span class="line">                            count[<span class="number">1</span>][data[<span class="string">'survived'</span>]] += data[<span class="string">'w'</span>]   <span class="comment"># 添加相应的权重</span></span><br><span class="line">                gini = <span class="number">0</span></span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2</span>):  <span class="comment"># 计算基尼指数</span></span><br><span class="line">                    gini += (count[i][<span class="number">0</span>] + count[i][<span class="number">1</span>])/len(datas) * (<span class="number">1</span> - (count[i][<span class="number">1</span>]/(count[i][<span class="number">0</span>] + count[i][<span class="number">1</span>]))**<span class="number">2</span>)</span><br><span class="line">                gini *= rho   <span class="comment"># 乘以rho</span></span><br><span class="line">                gini_temp.append(gini)</span><br><span class="line">            gini = min(gini_temp)   <span class="comment"># 求出最小的基尼指数</span></span><br><span class="line">            age = ageList[gini_temp.index(gini)]   <span class="comment"># 求出最小基尼指数相应的划分age</span></span><br><span class="line">            giniList.append(gini)</span><br><span class="line">        </span><br><span class="line">        gini = min(giniList)  <span class="comment"># 求出所有划分可能中最小的基尼指数</span></span><br><span class="line">        a = attributes[giniList.index(gini)]  <span class="comment"># 求出对应的划分属性</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> a == <span class="string">'age'</span>:</span><br><span class="line">            <span class="keyword">return</span> gini, a, age <span class="comment"># 连续值情况下，返回对应的划分边界</span></span><br><span class="line">        <span class="keyword">elif</span> a ==<span class="string">'fare'</span>:</span><br><span class="line">            <span class="keyword">return</span> gini, a, fare <span class="comment"># 连续值情况下，返回对应的划分边界</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> gini, a, <span class="number">0</span></span><br></pre></td></tr></table></figure>
<p><strong>预测函数</strong>：构建好了决策树后用于预测（注意预测过程中，样本缺失值的处理，忘了可以查看前文缺失值的处理）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, node, predictData)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> node.leaf == <span class="number">1</span>:  <span class="comment"># 当前结点为叶子结点时</span></span><br><span class="line">        <span class="keyword">return</span> node.kind</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        a = node.attribute</span><br><span class="line">        <span class="keyword">if</span> a == <span class="string">'embarked'</span>:</span><br><span class="line">            <span class="keyword">if</span> predictData[a] == <span class="number">0</span>:    <span class="comment"># 当前结点此值为缺失值时</span></span><br><span class="line">                <span class="keyword">return</span> self.predict(node.son[node.prior], predictData)</span><br><span class="line">            <span class="keyword">else</span>:  <span class="comment"># 如果不是缺失值，则按属性划分</span></span><br><span class="line">                <span class="keyword">return</span> self.predict(node.son[predictData[a] - <span class="number">1</span>], predictData)</span><br><span class="line">        <span class="keyword">elif</span> a == <span class="string">'fare'</span>:</span><br><span class="line">            <span class="keyword">if</span> predictData[a] &lt; node.boundary:   <span class="comment"># 连续值处理</span></span><br><span class="line">                <span class="keyword">return</span> self.predict(node.son[<span class="number">0</span>], predictData)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> self.predict(node.son[<span class="number">1</span>], predictData)</span><br><span class="line">        <span class="keyword">elif</span> a == <span class="string">'age'</span>:</span><br><span class="line">            <span class="keyword">if</span> predictData[a] == <span class="number">0</span>:        <span class="comment"># 当前结点此值为缺失值</span></span><br><span class="line">                <span class="keyword">return</span> self.predict(node.son[node.prior], predictData)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">if</span> predictData[a] &lt; node.boundary:   <span class="comment"># 连续值处理</span></span><br><span class="line">                    <span class="keyword">return</span> self.predict(node.son[<span class="number">0</span>], predictData)</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="keyword">return</span> self.predict(node.son[<span class="number">1</span>], predictData)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> self.predict(node.son[predictData[a]], predictData)</span><br></pre></td></tr></table></figure>
<p><strong>后剪枝</strong>：这部分包含了两个函数，一个用于获取后根遍历的所有路径，一个根据获取的路径来依次尝试删除结点，并且比较输入准确率的大小，从而决定是否剪枝。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">postOrderTraverse</span><span class="params">(self, node, route, traverseList)</span>:</span>  <span class="comment"># 后根遍历所有的非叶子结点</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(node.son)):</span><br><span class="line">        <span class="keyword">if</span> node.son[i].leaf != <span class="number">1</span>:</span><br><span class="line">            temp_route = deepcopy(route)  <span class="comment"># 如果其子节点不是叶子结点，则继续递归访问</span></span><br><span class="line">            temp_route.append(i)</span><br><span class="line">            self.postOrderTraverse(node.son[i], temp_route, traverseList)</span><br><span class="line">    traverseList.append(route)   <span class="comment"># 最后添加当前结点路径</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">postPruning</span><span class="params">(self, curAccuracy, devData)</span>:</span>   <span class="comment"># 后剪枝</span></span><br><span class="line">    traverseList = []</span><br><span class="line">    self.postOrderTraverse(node = self.root, route = [],traverseList = traverseList)   <span class="comment"># 获取后根遍历的路径</span></span><br><span class="line">    tempNode = Node(<span class="string">''</span>)</span><br><span class="line">    <span class="keyword">for</span> route <span class="keyword">in</span> traverseList:  <span class="comment"># 依次遍历路径，按照后根遍历的顺序进行后剪枝</span></span><br><span class="line">        tempNode = self.root</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> route:</span><br><span class="line">            tempNode = tempNode.son[i]  <span class="comment"># 遍历到目标结点</span></span><br><span class="line">        tempNode.leaf = <span class="number">1</span></span><br><span class="line">        count = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> devData:</span><br><span class="line">            <span class="keyword">if</span> data[<span class="string">'survived'</span>] == cartTree.predict(cartTree.root, data):</span><br><span class="line">                count +=<span class="number">1</span></span><br><span class="line">        Accuracy = count/len(devData)  <span class="comment"># 计算当前在验证集上的正确率</span></span><br><span class="line">        <span class="keyword">if</span> Accuracy &lt;= curAccuracy:  <span class="comment"># 如果正确率降低了，那么撤回修改</span></span><br><span class="line">            tempNode.leaf = <span class="number">0</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            curAccuracy = Accuracy  <span class="comment"># 如果正确率上升了，执行修改并且更新当前的准确率</span></span><br></pre></td></tr></table></figure>
<p><strong>决策树可视化</strong>：一个十分简陋的决策树可视化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">showTree</span><span class="params">(self, node, layer)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> node.leaf == <span class="number">0</span>:</span><br><span class="line">        show_str = str(layer)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(layer):</span><br><span class="line">            show_str += <span class="string">'-*'</span></span><br><span class="line">        show_str += node.attribute</span><br><span class="line">        print(show_str)</span><br><span class="line">    <span class="keyword">for</span> son <span class="keyword">in</span> node.son:</span><br><span class="line">        self.showTree(son, layer+<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<h4 id="2-3-决策树初始化"><a href="#2-3-决策树初始化" class="headerlink" title="2.3 决策树初始化"></a>2.3 决策树初始化</h4><p>决策树类都定义好了，就开始初始化吧</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cartTree = decisionTree()</span><br><span class="line">cartTree.root = cartTree.createTree(attributes = [<span class="string">'pclass'</span>, <span class="string">'sex'</span>, <span class="string">'age'</span>, <span class="string">'sibsp'</span>, <span class="string">'parch'</span>, <span class="string">'fare'</span>, <span class="string">'cabin'</span>, <span class="string">'embarked'</span>], datas = trainData)</span><br><span class="line">cartTree.showTree(cartTree.root, <span class="number">1</span>)  <span class="comment"># 查看决策树</span></span><br></pre></td></tr></table></figure>
<p>输出结果（前面的数字代表在第几层，最后表示当前结点的最优划分属性）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line">1-*pclass</span><br><span class="line">2-*-*sex</span><br><span class="line">3-*-*-*age</span><br><span class="line">4-*-*-*-*fare</span><br><span class="line">5-*-*-*-*-*cabin</span><br><span class="line">4-*-*-*-*sibsp</span><br><span class="line">5-*-*-*-*-*fare</span><br><span class="line">6-*-*-*-*-*-*cabin</span><br><span class="line">6-*-*-*-*-*-*cabin</span><br><span class="line">5-*-*-*-*-*parch</span><br><span class="line">6-*-*-*-*-*-*fare</span><br><span class="line">7-*-*-*-*-*-*-*cabin</span><br><span class="line">6-*-*-*-*-*-*fare</span><br><span class="line">3-*-*-*age</span><br><span class="line">4-*-*-*-*fare</span><br><span class="line">4-*-*-*-*sibsp</span><br><span class="line">5-*-*-*-*-*fare</span><br><span class="line">5-*-*-*-*-*fare</span><br><span class="line">6-*-*-*-*-*-*cabin</span><br><span class="line">2-*-*sex</span><br><span class="line">3-*-*-*age</span><br><span class="line">4-*-*-*-*fare</span><br><span class="line">5-*-*-*-*-*cabin</span><br><span class="line">4-*-*-*-*fare</span><br><span class="line">5-*-*-*-*-*cabin</span><br><span class="line">6-*-*-*-*-*-*embarked</span><br><span class="line">5-*-*-*-*-*cabin</span><br><span class="line">3-*-*-*age</span><br><span class="line">4-*-*-*-*sibsp</span><br><span class="line">5-*-*-*-*-*fare</span><br><span class="line">6-*-*-*-*-*-*cabin</span><br><span class="line">7-*-*-*-*-*-*-*embarked</span><br><span class="line">5-*-*-*-*-*parch</span><br><span class="line">6-*-*-*-*-*-*fare</span><br><span class="line">6-*-*-*-*-*-*fare</span><br><span class="line">4-*-*-*-*fare</span><br><span class="line">2-*-*sex</span><br><span class="line">3-*-*-*age</span><br><span class="line">4-*-*-*-*sibsp</span><br><span class="line">5-*-*-*-*-*fare</span><br><span class="line">6-*-*-*-*-*-*cabin</span><br><span class="line">7-*-*-*-*-*-*-*embarked</span><br><span class="line">6-*-*-*-*-*-*cabin</span><br><span class="line">7-*-*-*-*-*-*-*embarked</span><br><span class="line">5-*-*-*-*-*fare</span><br><span class="line">6-*-*-*-*-*-*embarked</span><br><span class="line">6-*-*-*-*-*-*embarked</span><br><span class="line">4-*-*-*-*sibsp</span><br><span class="line">5-*-*-*-*-*fare</span><br><span class="line">6-*-*-*-*-*-*cabin</span><br><span class="line">7-*-*-*-*-*-*-*embarked</span><br><span class="line">5-*-*-*-*-*parch</span><br><span class="line">6-*-*-*-*-*-*fare</span><br><span class="line">7-*-*-*-*-*-*-*embarked</span><br><span class="line">6-*-*-*-*-*-*fare</span><br><span class="line">3-*-*-*age</span><br><span class="line">4-*-*-*-*sibsp</span><br><span class="line">5-*-*-*-*-*fare</span><br><span class="line">6-*-*-*-*-*-*cabin</span><br><span class="line">7-*-*-*-*-*-*-*embarked</span><br><span class="line">5-*-*-*-*-*fare</span><br><span class="line">6-*-*-*-*-*-*cabin</span><br><span class="line">7-*-*-*-*-*-*-*embarked</span><br><span class="line">5-*-*-*-*-*fare</span><br><span class="line">4-*-*-*-*sibsp</span><br><span class="line">5-*-*-*-*-*parch</span><br><span class="line">6-*-*-*-*-*-*fare</span><br><span class="line">7-*-*-*-*-*-*-*embarked</span><br><span class="line">7-*-*-*-*-*-*-*embarked</span><br><span class="line">6-*-*-*-*-*-*fare</span><br><span class="line">7-*-*-*-*-*-*-*cabin</span><br><span class="line">8-*-*-*-*-*-*-*-*embarked</span><br><span class="line">6-*-*-*-*-*-*fare</span><br><span class="line">5-*-*-*-*-*parch</span><br><span class="line">6-*-*-*-*-*-*fare</span><br><span class="line">6-*-*-*-*-*-*fare</span><br><span class="line">7-*-*-*-*-*-*-*cabin</span><br><span class="line">8-*-*-*-*-*-*-*-*embarked</span><br><span class="line">6-*-*-*-*-*-*fare</span><br><span class="line">5-*-*-*-*-*fare</span><br></pre></td></tr></table></figure>
<h4 id="2-4-在验证集上检验准确率"><a href="#2-4-在验证集上检验准确率" class="headerlink" title="2.4 在验证集上检验准确率"></a>2.4 在验证集上检验准确率</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">count = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> devData:</span><br><span class="line">    <span class="keyword">if</span> data[<span class="string">'survived'</span>] == cartTree.predict(cartTree.root, data):</span><br><span class="line">        count +=<span class="number">1</span></span><br><span class="line">Accuracy = count/len(devData)</span><br><span class="line">print(<span class="string">'验证集准确率：'</span>+ str(Accuracy))</span><br></pre></td></tr></table></figure>
<p>输出结果:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">验证集准确率：0.78</span><br></pre></td></tr></table></figure>
<h4 id="2-5-进行后剪枝后的准确率"><a href="#2-5-进行后剪枝后的准确率" class="headerlink" title="2.5 进行后剪枝后的准确率"></a>2.5 进行后剪枝后的准确率</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cartTree.postPruning(curAccuracy = Accuracy, devData = devData)</span><br><span class="line">count = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> devData:</span><br><span class="line">    <span class="keyword">if</span> data[<span class="string">'survived'</span>] == cartTree.predict(cartTree.root, data):</span><br><span class="line">        count +=<span class="number">1</span></span><br><span class="line">Accuracy = count/len(devData)</span><br><span class="line">print(<span class="string">'验证集准确率：'</span>+ str(Accuracy))</span><br></pre></td></tr></table></figure>
<p>输出结果（可以看到后剪枝后，验证集上的准确率提升了）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">验证集准确率：0.8</span><br></pre></td></tr></table></figure>
<h4 id="2-6-查看剪枝后的决策树"><a href="#2-6-查看剪枝后的决策树" class="headerlink" title="2.6 查看剪枝后的决策树"></a>2.6 查看剪枝后的决策树</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cartTree.showTree(cartTree.root, <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>输出结果（剪枝后，相比于之前的决策树，少了一些分支）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line">1-*pclass</span><br><span class="line">2-*-*sex</span><br><span class="line">3-*-*-*age</span><br><span class="line">4-*-*-*-*fare</span><br><span class="line">5-*-*-*-*-*cabin</span><br><span class="line">4-*-*-*-*sibsp</span><br><span class="line">5-*-*-*-*-*fare</span><br><span class="line">6-*-*-*-*-*-*cabin</span><br><span class="line">6-*-*-*-*-*-*cabin</span><br><span class="line">5-*-*-*-*-*parch</span><br><span class="line">6-*-*-*-*-*-*fare</span><br><span class="line">7-*-*-*-*-*-*-*cabin</span><br><span class="line">6-*-*-*-*-*-*fare</span><br><span class="line">3-*-*-*age</span><br><span class="line">4-*-*-*-*fare</span><br><span class="line">4-*-*-*-*sibsp</span><br><span class="line">5-*-*-*-*-*fare</span><br><span class="line">5-*-*-*-*-*fare</span><br><span class="line">6-*-*-*-*-*-*cabin</span><br><span class="line">2-*-*sex</span><br><span class="line">3-*-*-*age</span><br><span class="line">4-*-*-*-*fare</span><br><span class="line">5-*-*-*-*-*cabin</span><br><span class="line">4-*-*-*-*fare</span><br><span class="line">5-*-*-*-*-*cabin</span><br><span class="line">6-*-*-*-*-*-*embarked</span><br><span class="line">5-*-*-*-*-*cabin</span><br><span class="line">3-*-*-*age</span><br><span class="line">4-*-*-*-*sibsp</span><br><span class="line">5-*-*-*-*-*fare</span><br><span class="line">6-*-*-*-*-*-*cabin</span><br><span class="line">7-*-*-*-*-*-*-*embarked</span><br><span class="line">5-*-*-*-*-*parch</span><br><span class="line">6-*-*-*-*-*-*fare</span><br><span class="line">6-*-*-*-*-*-*fare</span><br><span class="line">4-*-*-*-*fare</span><br><span class="line">2-*-*sex</span><br><span class="line">3-*-*-*age</span><br><span class="line">4-*-*-*-*sibsp</span><br><span class="line">5-*-*-*-*-*fare</span><br><span class="line">6-*-*-*-*-*-*cabin</span><br><span class="line">7-*-*-*-*-*-*-*embarked</span><br><span class="line">6-*-*-*-*-*-*cabin</span><br><span class="line">7-*-*-*-*-*-*-*embarked</span><br><span class="line">5-*-*-*-*-*fare</span><br><span class="line">6-*-*-*-*-*-*embarked</span><br><span class="line">6-*-*-*-*-*-*embarked</span><br><span class="line">4-*-*-*-*sibsp</span><br><span class="line">5-*-*-*-*-*fare</span><br><span class="line">6-*-*-*-*-*-*cabin</span><br><span class="line">7-*-*-*-*-*-*-*embarked</span><br><span class="line">5-*-*-*-*-*parch</span><br><span class="line">6-*-*-*-*-*-*fare</span><br><span class="line">7-*-*-*-*-*-*-*embarked</span><br><span class="line">6-*-*-*-*-*-*fare</span><br><span class="line">3-*-*-*age</span><br><span class="line">4-*-*-*-*sibsp</span><br><span class="line">5-*-*-*-*-*fare</span><br><span class="line">6-*-*-*-*-*-*cabin</span><br><span class="line">7-*-*-*-*-*-*-*embarked</span><br><span class="line">6-*-*-*-*-*-*cabin</span><br><span class="line">7-*-*-*-*-*-*-*embarked</span><br><span class="line">5-*-*-*-*-*fare</span><br><span class="line">4-*-*-*-*sibsp</span><br><span class="line">5-*-*-*-*-*parch</span><br><span class="line">6-*-*-*-*-*-*fare</span><br><span class="line">7-*-*-*-*-*-*-*embarked</span><br><span class="line">7-*-*-*-*-*-*-*embarked</span><br><span class="line">6-*-*-*-*-*-*fare</span><br><span class="line">7-*-*-*-*-*-*-*cabin</span><br><span class="line">8-*-*-*-*-*-*-*-*embarked</span><br><span class="line">6-*-*-*-*-*-*fare</span><br><span class="line">6-*-*-*-*-*-*fare</span><br><span class="line">6-*-*-*-*-*-*fare</span><br><span class="line">7-*-*-*-*-*-*-*cabin</span><br><span class="line">6-*-*-*-*-*-*fare</span><br><span class="line">5-*-*-*-*-*fare</span><br></pre></td></tr></table></figure>
<h3 id="3-预测测试集"><a href="#3-预测测试集" class="headerlink" title="3. 预测测试集"></a>3. 预测测试集</h3><h4 id="3-1-加载测试集"><a href="#3-1-加载测试集" class="headerlink" title="3.1 加载测试集"></a>3.1 加载测试集</h4><p>其实和加载训练数据的函数差不多，但是没有survived特征，并且不需要设置权重w了（因为只需要进行预测）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadTestData</span><span class="params">(filename)</span>:</span></span><br><span class="line">    data = []</span><br><span class="line">    f = list(csv.reader(open(filename, <span class="string">'r'</span>)))[<span class="number">1</span>:]   <span class="comment"># 读取去掉表头的部分</span></span><br><span class="line">    embarkedDist = &#123;<span class="string">'C'</span>:<span class="number">1</span>, <span class="string">'Q'</span>:<span class="number">2</span>, <span class="string">'S'</span>:<span class="number">3</span>&#125;    <span class="comment"># 无缺失值时，'C':1, 'Q':2, 'S':3</span></span><br><span class="line">    sibspParch = [<span class="number">1</span>, <span class="number">2</span>]</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">        <span class="keyword">if</span> int(line[<span class="number">5</span>]) == <span class="number">0</span>:  <span class="comment"># 转化sibsp</span></span><br><span class="line">            sibsp = <span class="number">0</span></span><br><span class="line">        <span class="keyword">elif</span> int(line[<span class="number">5</span>]) &lt;= <span class="number">2</span>:</span><br><span class="line">            sibsp = <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            sibsp = <span class="number">2</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> int(line[<span class="number">6</span>]) == <span class="number">0</span>:   <span class="comment"># 转化sibsp</span></span><br><span class="line">            parch = <span class="number">0</span></span><br><span class="line">        <span class="keyword">elif</span> int(line[<span class="number">6</span>]) &lt;= <span class="number">2</span>:</span><br><span class="line">            parch = <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            parch = <span class="number">2</span></span><br><span class="line">        dataDist=&#123;<span class="string">'pclass'</span>: int(line[<span class="number">1</span>]) - <span class="number">1</span>,</span><br><span class="line">             <span class="string">'sex'</span>: <span class="number">0</span> <span class="keyword">if</span> line[<span class="number">3</span>] == <span class="string">'male'</span> <span class="keyword">else</span> <span class="number">1</span>,   <span class="comment"># male:0  female:1</span></span><br><span class="line">             <span class="string">'age'</span>: <span class="number">0</span> <span class="keyword">if</span> len(line[<span class="number">4</span>]) == <span class="number">0</span> <span class="keyword">else</span> float(line[<span class="number">4</span>]),   <span class="comment"># 有缺失值保存为0</span></span><br><span class="line">             <span class="string">'sibsp'</span>: sibsp,</span><br><span class="line">             <span class="string">'parch'</span>: parch,</span><br><span class="line">             <span class="string">'fare'</span>: <span class="number">0</span> <span class="keyword">if</span> len(line[<span class="number">8</span>]) == <span class="number">0</span> <span class="keyword">else</span> float(line[<span class="number">8</span>]),  <span class="comment"># 测试集中发现有一个缺失值</span></span><br><span class="line">             <span class="string">'cabin'</span>: <span class="number">0</span> <span class="keyword">if</span> len(line[<span class="number">9</span>]) == <span class="number">0</span> <span class="keyword">else</span> <span class="number">1</span>,   <span class="comment"># 有缺失值：0  无缺失值：1</span></span><br><span class="line">             <span class="string">'embarked'</span>: <span class="number">0</span> <span class="keyword">if</span> len(line[<span class="number">10</span>]) == <span class="number">0</span> <span class="keyword">else</span> embarkedDist[line[<span class="number">10</span>]]&#125;   <span class="comment"># 有缺失值：0  无缺失值保存为1、2、3</span></span><br><span class="line">        data.append(dataDist)</span><br><span class="line">    <span class="keyword">return</span> data</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">testData = loadTestData(<span class="string">'test.csv'</span>)</span><br><span class="line">print(testData[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<p>输出结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#39;pclass&#39;: 2, &#39;sex&#39;: 0, &#39;age&#39;: 34.5, &#39;sibsp&#39;: 0, &#39;parch&#39;: 0, &#39;fare&#39;: 7.8292, &#39;cabin&#39;: 0, &#39;embarked&#39;: 2&#125;</span><br></pre></td></tr></table></figure>
<h4 id="3-2-进行预测，并将结果写入csv文件"><a href="#3-2-进行预测，并将结果写入csv文件" class="headerlink" title="3.2 进行预测，并将结果写入csv文件"></a>3.2 进行预测，并将结果写入csv文件</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">predict = []</span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> testData:</span><br><span class="line">    predict.append(cartTree.predict(cartTree.root, data))</span><br><span class="line">f = open(<span class="string">'testPredict.csv'</span>,<span class="string">'w'</span>,encoding=<span class="string">'utf-8'</span>,newline=<span class="string">''</span> <span class="string">""</span>)</span><br><span class="line">csv_writer = csv.writer(f)</span><br><span class="line">csv_writer.writerow([<span class="string">'PassengerId'</span>,<span class="string">'Survived'</span>])</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">418</span>):</span><br><span class="line">    csv_writer.writerow([str(i+<span class="number">892</span>),str(predict[i])])</span><br><span class="line">f.close()</span><br></pre></td></tr></table></figure>
<h4 id="3-3-上传kaggle"><a href="#3-3-上传kaggle" class="headerlink" title="3.3 上传kaggle"></a>3.3 上传kaggle</h4><p>然后将写好的csv文件上传kaggle即可。</p>
<p><strong>后剪枝处理前</strong>：（正确率为0.74401）</p>
<p><img src="https://s1.ax1x.com/2020/07/12/UGPP1I.png" alt="UGPP1I.png"></p>
<p><strong>后剪枝处理后</strong>：（正确率为0.77990，可以看到有明显提升）</p>
<p><img src="https://s1.ax1x.com/2020/07/13/UGU8rq.png" alt="UGU8rq.png"></p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/%E7%AE%97%E6%B3%95/" rel="tag"><i class="fa fa-tag"></i> 算法</a>
          
            <a href="/tags/python/" rel="tag"><i class="fa fa-tag"></i> python</a>
          
            <a href="/tags/%E5%88%86%E7%B1%BB/" rel="tag"><i class="fa fa-tag"></i> 分类</a>
          
            <a href="/tags/kaggle/" rel="tag"><i class="fa fa-tag"></i> kaggle</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/07/13/Logistic%E5%9B%9E%E5%BD%92%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90%E5%92%8C%E5%AE%9E%E8%B7%B5/" rel="next" title="Logistic回归原理分析和实践">
                <i class="fa fa-chevron-left"></i> Logistic回归原理分析和实践
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2020/07/14/RCNN%E8%AF%A6%E8%A7%A3/" rel="prev" title="RCNN详解">
                RCNN详解 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div class="ds-thread" data-thread-key="2020/07/13/决策树原理分析与实践/"
           data-title="决策树原理分析与实践" data-url="http://yoursite.com/2020/07/13/%E5%86%B3%E7%AD%96%E6%A0%91%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90%E4%B8%8E%E5%AE%9E%E8%B7%B5/">
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="https://note.youdao.com/yws/api/personal/file/94706D7C9BE34FFEBAD4C35B311F0E38?method=download&shareKey=5a712edcc9469413b507c8ef9cf15513"
                alt="panfeng's blog" />
            
              <p class="site-author-name" itemprop="name">panfeng's blog</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives">
              
                  <span class="site-state-item-count">61</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">12</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">73</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/AgentGuo" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:841796600@qq.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#决策树原理分析与实践"><span class="nav-text">决策树原理分析与实践</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#原理分析"><span class="nav-text">原理分析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-简要介绍"><span class="nav-text">1.简要介绍</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-决策树的生成过程"><span class="nav-text">2.决策树的生成过程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-选择最优划分属性"><span class="nav-text">3.选择最优划分属性</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-信息增益（ID3决策树）"><span class="nav-text">3.1 信息增益（ID3决策树）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-2-增益率（C4-5决策树）"><span class="nav-text">3.2 增益率（C4.5决策树）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-3-基尼指数（CART决策树）"><span class="nav-text">3.3 基尼指数（CART决策树）</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-拓展部分"><span class="nav-text">4.拓展部分</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#4-1-预剪枝"><span class="nav-text">4.1 预剪枝</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-2-后剪枝"><span class="nav-text">4.2 后剪枝</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-3-连续值处理"><span class="nav-text">4.3 连续值处理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-4-缺失值处理"><span class="nav-text">4.4 缺失值处理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-5-多变量决策树"><span class="nav-text">4.5 多变量决策树</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CART决策树实践"><span class="nav-text">CART决策树实践</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-数据加载"><span class="nav-text">1. 数据加载</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-构建决策树"><span class="nav-text">2. 构建决策树</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-1-结点定义"><span class="nav-text">2.1 结点定义</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-决策树定义"><span class="nav-text">2.2 决策树定义</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-3-决策树初始化"><span class="nav-text">2.3 决策树初始化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-4-在验证集上检验准确率"><span class="nav-text">2.4 在验证集上检验准确率</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-5-进行后剪枝后的准确率"><span class="nav-text">2.5 进行后剪枝后的准确率</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-6-查看剪枝后的决策树"><span class="nav-text">2.6 查看剪枝后的决策树</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-预测测试集"><span class="nav-text">3. 预测测试集</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-加载测试集"><span class="nav-text">3.1 加载测试集</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-2-进行预测，并将结果写入csv文件"><span class="nav-text">3.2 进行预测，并将结果写入csv文件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-3-上传kaggle"><span class="nav-text">3.3 上传kaggle</span></a></li></ol></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">panfeng's blog</span>

  
</div>

<!--

  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>

 -->

<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共99.2k字</span>
</div>
        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"your-duoshuo-shortname"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>

  
    
    
    <script src="/lib/ua-parser-js/dist/ua-parser.min.js?v=0.7.9"></script>
    <script src="/js/src/hook-duoshuo.js"></script>
  


















  





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("GksJHYNBz0VjRrAQjwNpruiC-gzGzoHsz", "0pYCKkFIF1OaexePM7yvqmnf");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/z16.model.json"},"display":{"position":"left","width":270,"height":540},"mobile":{"show":true},"react":{"opacity":0.7},"log":false});</script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end --></body>
</html>
